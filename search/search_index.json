{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"caches/","text":"Cache Options Supported Caches There are several cache types supported by Trickster In-Memory (default) Filesystem bbolt BadgerDB Redis (basic, cluster, and sentinel) The sample configuration ( cmd/trickster/conf/example.conf ) demonstrates how to select and configure a particular cache type, as well as how to configure generic cache configurations such as Retention Policy. In-Memory In-Memory Cache is the default type that Trickster will implement if none of the other cache types are configured. The In-Memory cache utilizes a Golang sync.Map object for caching, which ensures atomic reads/writes against the cache with no possibility of data collisions. This option is good for both development environments and most smaller dashboard deployments. When running Trickster in a Docker container, ensure your node hosting the container has enough memory available to accommodate the cache size of your footprint, or your container may be shut down by Docker with an Out of Memory error (#137). Similarly, when orchestrating with Kubernetes, set resource allocations accordingly. Filesystem The Filesystem Cache is a popular option when you have larger dashboard setup (e.g., many different dashboards with many varying queries, Dashboard as a Service for several teams running their own Prometheus instances, etc.) that requires more storage space than you wish to accommodate in RAM. A Filesystem Cache configuration keeps the Trickster RAM footprint small, and is generally comparable in performance to In-Memory. Trickster performance can be degraded when using the Filesystem Cache if disk i/o becomes a bottleneck (e.g., many concurrent dashboard users). The default Filesystem Cache path is /tmp/trickster . The sample configuration demonstrates how to specify a custom cache path. Ensure that the user account running Trickster has read/write access to the custom directory or the application will exit on startup upon testing filesystem access. All users generally have access to /tmp so there is no concern about permissions in the default case. bbolt The BoltDB Cache is a popular key/value store, created by Ben Johnson . CoreOS's bbolt fork is the version implemented in Trickster. A bbolt store is a filesystem-based solution that stores the entire database in a single file. Trickster, by default, creates the database at trickster.db and uses a bucket name of 'trickster' for storing key/value data. See the example config file for details on customizing this aspect of your Trickster deployment. The same guidance about filesystem permissions described in the Filesystem Cache section above apply to a bbolt Cache. BadgerDB BadgerDB works similarly to bbolt, in that it is a filesystem-based key/value datastore. BadgerDB provides its own native object lifecycle management (TTL) and other additional features that distinguish it from bbolt. See the configuration for more info on using BadgerDB with Trickster. Redis Note: Trickster does not come with a Redis server. You must provide a pre-existing Redis endpoint for Trickster to use. Redis is a good option for larger dashboard setups that also have heavy user traffic, where you might see degraded performance with a Filesystem Cache. This allows Trickster to scale better than a Filesystem Cache, but you will need to provide your own Redis instance at which to point your Trickster instance. The default Redis endpoint is redis:6379 , and should work for most docker and kube deployments with containers or services named redis . The sample configuration demonstrates how to customize the Redis endpoint. In addition to supporting TCP endpoints, Trickster supports Unix sockets for Trickster and Redis running on the same VM or bare-metal host. Ensure that your Redis instance is located close to your Trickster instance in order to minimize additional roundtrip latency. In addition to basic Redis, Trickster also supports Redis Cluster and Redis Sentinel. Refer to the sample configuration for customizing the Redis client type. Purging the Cache Cache purges should not be necessary, but in the event that you wish to do so, the following steps should be followed based upon your selected Cache Type. A future release will provide a mechanism to fully purge the cache (regardless of the underlying cache type) without stopping a running Trickster instance. Purging In-Memory Cache Since this cache type runs inside the virtual memory allocated to the Trickster process, bouncing the Trickster process or container will effectively purge the cache. Purging Filesystem Cache To completely purge a Filesystem-based Cache, you will need to: Docker/Kube: delete the Trickster container (or mounted volume) and run a new one Metal/VM: Stop the Trickster process and manually run rm -rf /tmp/trickster (or your custom-configured directory). Purging Redis Cache Connect to your Redis instance and issue a FLUSH command. Note that if your Redis instance supports more applications than Trickster, a FLUSH will clear the cache for all dependent applications. Purging bbolt Cache Stop the Trickster process and delete the configured bbolt file. Purging BadgerDB Cache Stop the Trickster process and delete the configured BadgerDB path. Cache Status Trickster reports several cache statuses in metrics, logs, and tracing, which are listed and described in the table below. Status Description kmiss The requested object was not in cache and was fetched from the origin rmiss Object is in cache, but the specific data range requested (timestamps or byte ranges) was not hit The object was fully cached and served from cache to the client phit The object was cached for some of the data requested, but not all nchit The response was served from the Negative Cache rhit The object was served from cache to the client, after being revalidated for freshness against the origin proxy-only The request was proxied 1:1 to the origin and not cached proxy-error The upstream request needed to fulfill an associated client request returned an error","title":"Cache Options"},{"location":"caches/#cache-options","text":"","title":"Cache Options"},{"location":"caches/#supported-caches","text":"There are several cache types supported by Trickster In-Memory (default) Filesystem bbolt BadgerDB Redis (basic, cluster, and sentinel) The sample configuration ( cmd/trickster/conf/example.conf ) demonstrates how to select and configure a particular cache type, as well as how to configure generic cache configurations such as Retention Policy.","title":"Supported Caches"},{"location":"caches/#in-memory","text":"In-Memory Cache is the default type that Trickster will implement if none of the other cache types are configured. The In-Memory cache utilizes a Golang sync.Map object for caching, which ensures atomic reads/writes against the cache with no possibility of data collisions. This option is good for both development environments and most smaller dashboard deployments. When running Trickster in a Docker container, ensure your node hosting the container has enough memory available to accommodate the cache size of your footprint, or your container may be shut down by Docker with an Out of Memory error (#137). Similarly, when orchestrating with Kubernetes, set resource allocations accordingly.","title":"In-Memory"},{"location":"caches/#filesystem","text":"The Filesystem Cache is a popular option when you have larger dashboard setup (e.g., many different dashboards with many varying queries, Dashboard as a Service for several teams running their own Prometheus instances, etc.) that requires more storage space than you wish to accommodate in RAM. A Filesystem Cache configuration keeps the Trickster RAM footprint small, and is generally comparable in performance to In-Memory. Trickster performance can be degraded when using the Filesystem Cache if disk i/o becomes a bottleneck (e.g., many concurrent dashboard users). The default Filesystem Cache path is /tmp/trickster . The sample configuration demonstrates how to specify a custom cache path. Ensure that the user account running Trickster has read/write access to the custom directory or the application will exit on startup upon testing filesystem access. All users generally have access to /tmp so there is no concern about permissions in the default case.","title":"Filesystem"},{"location":"caches/#bbolt","text":"The BoltDB Cache is a popular key/value store, created by Ben Johnson . CoreOS's bbolt fork is the version implemented in Trickster. A bbolt store is a filesystem-based solution that stores the entire database in a single file. Trickster, by default, creates the database at trickster.db and uses a bucket name of 'trickster' for storing key/value data. See the example config file for details on customizing this aspect of your Trickster deployment. The same guidance about filesystem permissions described in the Filesystem Cache section above apply to a bbolt Cache.","title":"bbolt"},{"location":"caches/#badgerdb","text":"BadgerDB works similarly to bbolt, in that it is a filesystem-based key/value datastore. BadgerDB provides its own native object lifecycle management (TTL) and other additional features that distinguish it from bbolt. See the configuration for more info on using BadgerDB with Trickster.","title":"BadgerDB"},{"location":"caches/#redis","text":"Note: Trickster does not come with a Redis server. You must provide a pre-existing Redis endpoint for Trickster to use. Redis is a good option for larger dashboard setups that also have heavy user traffic, where you might see degraded performance with a Filesystem Cache. This allows Trickster to scale better than a Filesystem Cache, but you will need to provide your own Redis instance at which to point your Trickster instance. The default Redis endpoint is redis:6379 , and should work for most docker and kube deployments with containers or services named redis . The sample configuration demonstrates how to customize the Redis endpoint. In addition to supporting TCP endpoints, Trickster supports Unix sockets for Trickster and Redis running on the same VM or bare-metal host. Ensure that your Redis instance is located close to your Trickster instance in order to minimize additional roundtrip latency. In addition to basic Redis, Trickster also supports Redis Cluster and Redis Sentinel. Refer to the sample configuration for customizing the Redis client type.","title":"Redis"},{"location":"caches/#purging-the-cache","text":"Cache purges should not be necessary, but in the event that you wish to do so, the following steps should be followed based upon your selected Cache Type. A future release will provide a mechanism to fully purge the cache (regardless of the underlying cache type) without stopping a running Trickster instance.","title":"Purging the Cache"},{"location":"caches/#purging-in-memory-cache","text":"Since this cache type runs inside the virtual memory allocated to the Trickster process, bouncing the Trickster process or container will effectively purge the cache.","title":"Purging In-Memory Cache"},{"location":"caches/#purging-filesystem-cache","text":"To completely purge a Filesystem-based Cache, you will need to: Docker/Kube: delete the Trickster container (or mounted volume) and run a new one Metal/VM: Stop the Trickster process and manually run rm -rf /tmp/trickster (or your custom-configured directory).","title":"Purging Filesystem Cache"},{"location":"caches/#purging-redis-cache","text":"Connect to your Redis instance and issue a FLUSH command. Note that if your Redis instance supports more applications than Trickster, a FLUSH will clear the cache for all dependent applications.","title":"Purging Redis Cache"},{"location":"caches/#purging-bbolt-cache","text":"Stop the Trickster process and delete the configured bbolt file.","title":"Purging bbolt Cache"},{"location":"caches/#purging-badgerdb-cache","text":"Stop the Trickster process and delete the configured BadgerDB path.","title":"Purging BadgerDB Cache"},{"location":"caches/#cache-status","text":"Trickster reports several cache statuses in metrics, logs, and tracing, which are listed and described in the table below. Status Description kmiss The requested object was not in cache and was fetched from the origin rmiss Object is in cache, but the specific data range requested (timestamps or byte ranges) was not hit The object was fully cached and served from cache to the client phit The object was cached for some of the data requested, but not all nchit The response was served from the Negative Cache rhit The object was served from cache to the client, after being revalidated for freshness against the origin proxy-only The request was proxied 1:1 to the origin and not cached proxy-error The upstream request needed to fulfill an associated client request returned an error","title":"Cache Status"},{"location":"clickhouse/","text":"ClickHouse Support Trickster 1.1 provides expanded support for accelerating ClickHouse queries that return time series data normally visualized on a dashboard. Acceleration works by using the Time Series Delta Proxy Cache to minimize the number and time range of queries to the upstream ClickHouse server. Scope of Support Trickster is tested with the ClickHouse DataSource Plugin for Grafana v1.9.3 by Vertamedia, and supports acceleration of queries constructed by this plugin using the plugin's built-in $timeSeries macro. Trickster also supports several other query formats that return \"time series like\" data. Because ClickHouse does not provide a golang-based query parser, Trickster uses custom parsing code on the incoming ClickHouse query to deconstruct its components, determine if it is cacheable and, if so, what elements are factored into the cache key derivation. Trickster also determines the requested time range and step based on the provided absolute values, in order to normalize the query before hashing the cache key. If you find query or response structures that are not yet supported, or providing inconsistent or unexpected results, we'd love for you to report those. We also always welcome any contributions around this functionality. To constitute a cacheable query, the first column expression in the main or any subquery must be in one of two specific forms in order to determine the timestamp column and step: Grafana Plugin Format SELECT intDiv(toUInt32(time_col, 60) * 60) [* 1000] [as] [alias] This is the approach used by the Grafana plugin. The time_col and/or alias is used to determine the requested time range from the WHERE or PREWHERE clause of the query. The argument to the ClickHouse intDiv function is the step value in seconds, since the toUInt32 function on a datetime column returns the Unix epoch seconds. ClickHouse Time Grouping Function SELECT toStartOf[Period](time_col) [as] [alias] This is the approach that uses the following optimized ClickHouse functions to group timeseries queries: toStartOfMinute toStartOfFiveMinute toStartOfTenMinutes toStartOfFifteenMinutes toStartOfHour toDate Again the time_col and/or alias is used to determine the request time range from the WHERE or PREWHERE clause, and the step is derived from the function name. Determining the requested time range Once the time column (or alias) and step are derived, Trickster parses each WHERE or PREWHERE clause to find comparison operations that mark the requested time range. To be cacheable, the WHERE clause must contain either a [timecol|alias] BETWEEN phrase or a [time_col|alias] >[=] phrase. The BETWEEN or >= arguments must be a parseable ClickHouse string date in the form 2006-01-02 15:04:05 , a a ten digit integer representing epoch seconds, or the now() ClickHouse function with optional subtraction. If a > phrase is used, a similar < phrase can be used to specify the end of the time period. If none is found, Trickster will still cache results up to the current time, but future queries must also have no end time phrase, or Trickster will be unable to find the correct cache key. Examples of cacheable time range WHERE clauses: WHERE t >= \"2020-10-15 00:00:00\" and t <= \"2020-10-16 12:00:00\" WHERE t >= \"2020-10-15 12:00:00\" and t < now() - 60 * 60 WHERE datetime BETWEEN 1574686300 AND 1574689900 Note that these values can be wrapped in the ClickHouse toDateTime function, but ClickHouse will make that conversion implicitly and it is not required. All string times are assumed to be UTC. Normalization and \"Fast Forwarding\" Trickster will always normalize the calculated time range to fit the step size, so small variations in the time range will still result in actual queries for the entire time \"bucket\". In addition, Trickster will not cache the results for the portion of the query that is still active -- i.e., within the current bucket or within the configured backfill tolerance setting (whichever is greater)","title":"ClickHouse Support"},{"location":"clickhouse/#clickhouse-support","text":"Trickster 1.1 provides expanded support for accelerating ClickHouse queries that return time series data normally visualized on a dashboard. Acceleration works by using the Time Series Delta Proxy Cache to minimize the number and time range of queries to the upstream ClickHouse server.","title":"ClickHouse Support"},{"location":"clickhouse/#scope-of-support","text":"Trickster is tested with the ClickHouse DataSource Plugin for Grafana v1.9.3 by Vertamedia, and supports acceleration of queries constructed by this plugin using the plugin's built-in $timeSeries macro. Trickster also supports several other query formats that return \"time series like\" data. Because ClickHouse does not provide a golang-based query parser, Trickster uses custom parsing code on the incoming ClickHouse query to deconstruct its components, determine if it is cacheable and, if so, what elements are factored into the cache key derivation. Trickster also determines the requested time range and step based on the provided absolute values, in order to normalize the query before hashing the cache key. If you find query or response structures that are not yet supported, or providing inconsistent or unexpected results, we'd love for you to report those. We also always welcome any contributions around this functionality. To constitute a cacheable query, the first column expression in the main or any subquery must be in one of two specific forms in order to determine the timestamp column and step:","title":"Scope of Support"},{"location":"clickhouse/#grafana-plugin-format","text":"SELECT intDiv(toUInt32(time_col, 60) * 60) [* 1000] [as] [alias] This is the approach used by the Grafana plugin. The time_col and/or alias is used to determine the requested time range from the WHERE or PREWHERE clause of the query. The argument to the ClickHouse intDiv function is the step value in seconds, since the toUInt32 function on a datetime column returns the Unix epoch seconds.","title":"Grafana Plugin Format"},{"location":"clickhouse/#clickhouse-time-grouping-function","text":"SELECT toStartOf[Period](time_col) [as] [alias] This is the approach that uses the following optimized ClickHouse functions to group timeseries queries: toStartOfMinute toStartOfFiveMinute toStartOfTenMinutes toStartOfFifteenMinutes toStartOfHour toDate Again the time_col and/or alias is used to determine the request time range from the WHERE or PREWHERE clause, and the step is derived from the function name.","title":"ClickHouse Time Grouping Function"},{"location":"clickhouse/#determining-the-requested-time-range","text":"Once the time column (or alias) and step are derived, Trickster parses each WHERE or PREWHERE clause to find comparison operations that mark the requested time range. To be cacheable, the WHERE clause must contain either a [timecol|alias] BETWEEN phrase or a [time_col|alias] >[=] phrase. The BETWEEN or >= arguments must be a parseable ClickHouse string date in the form 2006-01-02 15:04:05 , a a ten digit integer representing epoch seconds, or the now() ClickHouse function with optional subtraction. If a > phrase is used, a similar < phrase can be used to specify the end of the time period. If none is found, Trickster will still cache results up to the current time, but future queries must also have no end time phrase, or Trickster will be unable to find the correct cache key. Examples of cacheable time range WHERE clauses: WHERE t >= \"2020-10-15 00:00:00\" and t <= \"2020-10-16 12:00:00\" WHERE t >= \"2020-10-15 12:00:00\" and t < now() - 60 * 60 WHERE datetime BETWEEN 1574686300 AND 1574689900 Note that these values can be wrapped in the ClickHouse toDateTime function, but ClickHouse will make that conversion implicitly and it is not required. All string times are assumed to be UTC.","title":"Determining the requested time range"},{"location":"clickhouse/#normalization-and-fast-forwarding","text":"Trickster will always normalize the calculated time range to fit the step size, so small variations in the time range will still result in actual queries for the entire time \"bucket\". In addition, Trickster will not cache the results for the portion of the query that is still active -- i.e., within the current bucket or within the configured backfill tolerance setting (whichever is greater)","title":"Normalization and \"Fast Forwarding\""},{"location":"collapsed-forwarding/","text":"Collapsed Forwarding Collapsed Forwarding is feature common among Reverse Proxy Cache solutions like Squid, Varnish and Apache Traffic Server. It works by ensuring only a single request to the upstream origin is performed for any object on a cache miss or revalidation attempt, no matter how many users are requesting the object at the same time. Trickster has support for two types of Collapsed Forwarding: Basic (default) and Progressive Basic Collapsed Forwarding Basic Collapsed Forwarding is the default functionality for Trickster, and works by waitlisting all requests for a cacheable object while a cache miss is being serviced for the object, and then serving the waitlisted requests once the cache has been populated. The feature is further detailed in the following diagram: Progressive Collapsed Forwarding Progressive Collapsed Forwarding (PCF) is an improvement upon the basic version, in that it eliminates the waitlist and serves all simultaneous requests concurrently while the object is still downloading from the server, similar to Apache Traffic Server's \"read-while-write\" feature. This may be useful in low-latency applications such as DASH or HLS video delivery, since PCF minimizes Time to First Byte latency for extremely popular objects. The feature is further detailed in the following diagram: PCF for Proxy-Only Requests Trickster provides a unique feature that implements PCF in Proxy-Only configurations, to bring the benefits of Collapsed Forwarding to HTTP Paths that are not configured to be routed through the Reverse Proxy Cache. (See Paths documentation for more info on routing). The feature is further detailed in the following diagram: How to enable Progressive Collapsed Forwarding When configuring path configs as described in Paths Documentation you simply need to add progressive_collapsed_forwarding = true in any path config using the proxy or proxycache handlers. Example: [origins.test.paths] [origins.test.paths.thing1] path = '/test_path1/' match_type = 'prefix' handler = 'proxycache' progressive_collapsed_forwarding = true [origins.test.paths.thing2] path = '/test_path2/' match_type = 'prefix' handler = 'proxy' progressive_collapsed_forwarding = true See the example.conf for more configuration examples. How to test Progressive Collapsed Forwarding An easy way to test PCF is to set up your favorite file server to host a large file(Lighttpd, Nginx, Apache WS, etc.), In Trickster turn on PCF for that path config and try make simultaneous requests. If the networking between your machine and Trickster has enough bandwidth you should see both streaming at the equivalent rate as the origin request. Example: Run a Lighttpd instance or docker container on your local machine and make a large file available to be served Run Trickster locally Make multiple curl requests of the same object You should see the speed limited on the origin request by your disk IO, and your speed between Trickster limited by Memory/CPU","title":"Collapsed Forwarding"},{"location":"collapsed-forwarding/#collapsed-forwarding","text":"Collapsed Forwarding is feature common among Reverse Proxy Cache solutions like Squid, Varnish and Apache Traffic Server. It works by ensuring only a single request to the upstream origin is performed for any object on a cache miss or revalidation attempt, no matter how many users are requesting the object at the same time. Trickster has support for two types of Collapsed Forwarding: Basic (default) and Progressive","title":"Collapsed Forwarding"},{"location":"collapsed-forwarding/#basic-collapsed-forwarding","text":"Basic Collapsed Forwarding is the default functionality for Trickster, and works by waitlisting all requests for a cacheable object while a cache miss is being serviced for the object, and then serving the waitlisted requests once the cache has been populated. The feature is further detailed in the following diagram:","title":"Basic Collapsed Forwarding"},{"location":"collapsed-forwarding/#progressive-collapsed-forwarding","text":"Progressive Collapsed Forwarding (PCF) is an improvement upon the basic version, in that it eliminates the waitlist and serves all simultaneous requests concurrently while the object is still downloading from the server, similar to Apache Traffic Server's \"read-while-write\" feature. This may be useful in low-latency applications such as DASH or HLS video delivery, since PCF minimizes Time to First Byte latency for extremely popular objects. The feature is further detailed in the following diagram:","title":"Progressive Collapsed Forwarding"},{"location":"collapsed-forwarding/#pcf-for-proxy-only-requests","text":"Trickster provides a unique feature that implements PCF in Proxy-Only configurations, to bring the benefits of Collapsed Forwarding to HTTP Paths that are not configured to be routed through the Reverse Proxy Cache. (See Paths documentation for more info on routing). The feature is further detailed in the following diagram:","title":"PCF for Proxy-Only Requests"},{"location":"collapsed-forwarding/#how-to-enable-progressive-collapsed-forwarding","text":"When configuring path configs as described in Paths Documentation you simply need to add progressive_collapsed_forwarding = true in any path config using the proxy or proxycache handlers. Example: [origins.test.paths] [origins.test.paths.thing1] path = '/test_path1/' match_type = 'prefix' handler = 'proxycache' progressive_collapsed_forwarding = true [origins.test.paths.thing2] path = '/test_path2/' match_type = 'prefix' handler = 'proxy' progressive_collapsed_forwarding = true See the example.conf for more configuration examples.","title":"How to enable Progressive Collapsed Forwarding"},{"location":"collapsed-forwarding/#how-to-test-progressive-collapsed-forwarding","text":"An easy way to test PCF is to set up your favorite file server to host a large file(Lighttpd, Nginx, Apache WS, etc.), In Trickster turn on PCF for that path config and try make simultaneous requests. If the networking between your machine and Trickster has enough bandwidth you should see both streaming at the equivalent rate as the origin request. Example: Run a Lighttpd instance or docker container on your local machine and make a large file available to be served Run Trickster locally Make multiple curl requests of the same object You should see the speed limited on the origin request by your disk IO, and your speed between Trickster limited by Memory/CPU","title":"How to test Progressive Collapsed Forwarding"},{"location":"configuring/","text":"Configuring Trickster There are 3 ways to configure Trickster, listed here in the order of evaluation. Configuration File Environment Variables Command Line Arguments Note that while the Configuration file provides a very robust number of knobs you can adjust, the ENV and CLI Args options support only basic use cases. Internal Defaults Internal Defaults are set for all configuration values, and are overridden by the configuration methods described below. All Internal Defaults are described in cmd/trickster/conf/example.conf comments. Configuration File Trickster accepts a -config /path/to/trickster.conf command line argument to specify a custom path to a Trickster configuration file. If the provided path cannot be accessed by Trickster, it will exit with a fatal error. When a -config parameter is not provided, Trickster will check for the presence of a config file at /etc/trickster/trickster.conf and load it if present, or proceed with the Internal Defaults if not present. Refer to cmd/trickster/conf/example.conf for full documentation on format of a configuration file. Environment Variables Trickster will then check for and evaluate the following Environment Variables: TRK_ORIGIN_URL=http://prometheus.example.com:9090 - The default origin for proxying all http requests TRK_ORIGIN_TYPE=prometheus - The type of supported origin server TRK_LOG_LEVEL=INFO - Level of Logging that Trickster will output TRK_PROXY_PORT=8480 -Listener port for the HTTP Proxy Endpoint TRK_METRICS_PORT=8481 - Listener port for the Metrics and pprof debugging HTTP Endpoint Command Line Arguments Finally, Trickster will check for and evaluate the following Command Line Arguments: -log-level INFO - Level of Logging that Trickster will output -config /path/to/trickster.conf - See Configuration File section above -origin http://prometheus.example.com:9090 - The default origin for proxying all http requests -origin-type prometheus - The type of supported origin server -proxy-port 8480 - Listener port for the HTTP Proxy Endpoint -metrics-port 8481 - Listener port for the Metrics and pprof debugging HTTP Endpoint Configuration Validation Trickster can validate a configuration file by running trickster -validate-config -config /path/to/config . Trickster will load the configuration and exit with the validation result, without running the configuration. Reloading the Configuration Trickster can gracefully reload the configuration file from disk without impacting the uptime and responsiveness of the the application. Trickster provides 2 ways to reload the Trickster configuration: by requesting an HTTP endpoint, or by sending a SIGHUP (e.g., kill -1 $TRICKSTER_PID ) to the Trickster process. In both cases, the underlying running Configuration File must have been modified such that the last modified time of the file is different than from when it was previously loaded. Config Reload via SIGHUP Once you have made the desired modifications to your config file, send a SIGHUP to the Trickster process by running kill -1 $TRICKSTER_PID . The Trickster log will indicate whether the reload attempt was successful or not. Config Reload via HTTP Endpoint Trickster provides an HTTP Endpoint for viewing the running Configuration, as well as requesting a configuration reload. The reload endpoint is configured by default to listen on address 127.0.0.1 and port 8484 , at /trickster/config/reload . These values can be customized, as demonstrated in the example.conf. The examples in this section will assume the defaults. Set the port to -1 to disable the reload HTTP interface altogether. To reload the config, simply make a GET request to the reload endpoint. If the underlying configuration file has changed, the configuration will be reloaded, and the caller will receive a success response. If the underlying file has not chnaged, the caller will receive an unsuccessful response, and reloading will be disabled for the duration of the Reload Rate Limiter. By default, this is 3 seconds, but can be customized as demonstrated in the example config file. The Reload Rate Limiter applies to the HTTP interface only, and not SIGHUP. If an HTTP listener must spin down (e.g., the listen port is changed in the refreshed config), the old listener will remain alive for a period of time to allow existing connections to organically finish. This period is called the Drain Timeout and is configurable. Trickster uses 30 seconds by default. The Drain Timeout also applies to old log files, in the event that a new log filename has been provided. View the Running Configuration Trickster also provides a http://127.0.0.1:8484/trickster/config endpoint, which returns the toml output of the currently-running Trickster configuration. The TOML-formatted configuration will include all defaults populated, overlaid with any configuration file settings, command-line arguments and or applicable environment variables. This read-only interface is also available via the metrics endpoint, in the event that the reload endpoint has been disabled. This path is configurable as demonstrated in the example config file.","title":"Configuring Trickster"},{"location":"configuring/#configuring-trickster","text":"There are 3 ways to configure Trickster, listed here in the order of evaluation. Configuration File Environment Variables Command Line Arguments Note that while the Configuration file provides a very robust number of knobs you can adjust, the ENV and CLI Args options support only basic use cases.","title":"Configuring Trickster"},{"location":"configuring/#internal-defaults","text":"Internal Defaults are set for all configuration values, and are overridden by the configuration methods described below. All Internal Defaults are described in cmd/trickster/conf/example.conf comments.","title":"Internal Defaults"},{"location":"configuring/#configuration-file","text":"Trickster accepts a -config /path/to/trickster.conf command line argument to specify a custom path to a Trickster configuration file. If the provided path cannot be accessed by Trickster, it will exit with a fatal error. When a -config parameter is not provided, Trickster will check for the presence of a config file at /etc/trickster/trickster.conf and load it if present, or proceed with the Internal Defaults if not present. Refer to cmd/trickster/conf/example.conf for full documentation on format of a configuration file.","title":"Configuration File"},{"location":"configuring/#environment-variables","text":"Trickster will then check for and evaluate the following Environment Variables: TRK_ORIGIN_URL=http://prometheus.example.com:9090 - The default origin for proxying all http requests TRK_ORIGIN_TYPE=prometheus - The type of supported origin server TRK_LOG_LEVEL=INFO - Level of Logging that Trickster will output TRK_PROXY_PORT=8480 -Listener port for the HTTP Proxy Endpoint TRK_METRICS_PORT=8481 - Listener port for the Metrics and pprof debugging HTTP Endpoint","title":"Environment Variables"},{"location":"configuring/#command-line-arguments","text":"Finally, Trickster will check for and evaluate the following Command Line Arguments: -log-level INFO - Level of Logging that Trickster will output -config /path/to/trickster.conf - See Configuration File section above -origin http://prometheus.example.com:9090 - The default origin for proxying all http requests -origin-type prometheus - The type of supported origin server -proxy-port 8480 - Listener port for the HTTP Proxy Endpoint -metrics-port 8481 - Listener port for the Metrics and pprof debugging HTTP Endpoint","title":"Command Line Arguments"},{"location":"configuring/#configuration-validation","text":"Trickster can validate a configuration file by running trickster -validate-config -config /path/to/config . Trickster will load the configuration and exit with the validation result, without running the configuration.","title":"Configuration Validation"},{"location":"configuring/#reloading-the-configuration","text":"Trickster can gracefully reload the configuration file from disk without impacting the uptime and responsiveness of the the application. Trickster provides 2 ways to reload the Trickster configuration: by requesting an HTTP endpoint, or by sending a SIGHUP (e.g., kill -1 $TRICKSTER_PID ) to the Trickster process. In both cases, the underlying running Configuration File must have been modified such that the last modified time of the file is different than from when it was previously loaded.","title":"Reloading the Configuration"},{"location":"configuring/#config-reload-via-sighup","text":"Once you have made the desired modifications to your config file, send a SIGHUP to the Trickster process by running kill -1 $TRICKSTER_PID . The Trickster log will indicate whether the reload attempt was successful or not.","title":"Config Reload via SIGHUP"},{"location":"configuring/#config-reload-via-http-endpoint","text":"Trickster provides an HTTP Endpoint for viewing the running Configuration, as well as requesting a configuration reload. The reload endpoint is configured by default to listen on address 127.0.0.1 and port 8484 , at /trickster/config/reload . These values can be customized, as demonstrated in the example.conf. The examples in this section will assume the defaults. Set the port to -1 to disable the reload HTTP interface altogether. To reload the config, simply make a GET request to the reload endpoint. If the underlying configuration file has changed, the configuration will be reloaded, and the caller will receive a success response. If the underlying file has not chnaged, the caller will receive an unsuccessful response, and reloading will be disabled for the duration of the Reload Rate Limiter. By default, this is 3 seconds, but can be customized as demonstrated in the example config file. The Reload Rate Limiter applies to the HTTP interface only, and not SIGHUP. If an HTTP listener must spin down (e.g., the listen port is changed in the refreshed config), the old listener will remain alive for a period of time to allow existing connections to organically finish. This period is called the Drain Timeout and is configurable. Trickster uses 30 seconds by default. The Drain Timeout also applies to old log files, in the event that a new log filename has been provided.","title":"Config Reload via HTTP Endpoint"},{"location":"configuring/#view-the-running-configuration","text":"Trickster also provides a http://127.0.0.1:8484/trickster/config endpoint, which returns the toml output of the currently-running Trickster configuration. The TOML-formatted configuration will include all defaults populated, overlaid with any configuration file settings, command-line arguments and or applicable environment variables. This read-only interface is also available via the metrics endpoint, in the event that the reload endpoint has been disabled. This path is configurable as demonstrated in the example config file.","title":"View the Running Configuration"},{"location":"health/","text":"Health Checks Trickster Service Health - Ping Endpoint Trickster provides a /trickster/ping endpoint that returns a response of 200 OK and the word pong if Trickster is up and running. The /trickster/ping endpoint does not check any proxy configurations or upstream origins. The path to the Ping endpoint is configurable, see the configuration documentation for more information. Upstream Connection Health - Origin Health Endpoints Trickster offers health endpoints for monitoring the health of the Trickster service with respect to its upstream connection to origin servers. Each configured origin's health check path is /trickster/health/ORIGIN_NAME . For example, if your origin is named foo , you can perform a health check of the upstream URL at http://<trickster_address:port>/trickster/health/foo . The origin health path prefix /trickster/health/ is customizable. See the example.conf for more info. The behavior of a health request will vary based on the Origin Type, as each Origin Type implements a custom default health check behavior. For example, with Prometheus, Trickster makes a request to /query?query=up and (hopefully) receives a 200 OK , while for InfluxDB the request is to /ping which returns a 204 No Content . You can customize the behavior in the Trickster configuration. See the example.conf for guidance. The Origin-Specific default health check configurations should return a 200-range status code to indicate that the end-to-end health check to the origin was successful. Note that this behavior is not guaranteed when operating under user-provided health check configurations. The HTTP Reverse Proxy Cache origin type does not have a built-in health check, since those parameters can vary from origin to origin; it must be configured by the operator. Other Ways to Monitor Health In addition to the out-of-the-box health checks to determine up-or-down status, you may want to setup alarms and thresholds based on the metrics instrumented by Trickster. See metrics.md for collecting performance metrics about Trickster.","title":"Health Checks"},{"location":"health/#health-checks","text":"","title":"Health Checks"},{"location":"health/#trickster-service-health-ping-endpoint","text":"Trickster provides a /trickster/ping endpoint that returns a response of 200 OK and the word pong if Trickster is up and running. The /trickster/ping endpoint does not check any proxy configurations or upstream origins. The path to the Ping endpoint is configurable, see the configuration documentation for more information.","title":"Trickster Service Health - Ping Endpoint"},{"location":"health/#upstream-connection-health-origin-health-endpoints","text":"Trickster offers health endpoints for monitoring the health of the Trickster service with respect to its upstream connection to origin servers. Each configured origin's health check path is /trickster/health/ORIGIN_NAME . For example, if your origin is named foo , you can perform a health check of the upstream URL at http://<trickster_address:port>/trickster/health/foo . The origin health path prefix /trickster/health/ is customizable. See the example.conf for more info. The behavior of a health request will vary based on the Origin Type, as each Origin Type implements a custom default health check behavior. For example, with Prometheus, Trickster makes a request to /query?query=up and (hopefully) receives a 200 OK , while for InfluxDB the request is to /ping which returns a 204 No Content . You can customize the behavior in the Trickster configuration. See the example.conf for guidance. The Origin-Specific default health check configurations should return a 200-range status code to indicate that the end-to-end health check to the origin was successful. Note that this behavior is not guaranteed when operating under user-provided health check configurations. The HTTP Reverse Proxy Cache origin type does not have a built-in health check, since those parameters can vary from origin to origin; it must be configured by the operator.","title":"Upstream Connection Health - Origin Health Endpoints"},{"location":"health/#other-ways-to-monitor-health","text":"In addition to the out-of-the-box health checks to determine up-or-down status, you may want to setup alarms and thresholds based on the metrics instrumented by Trickster. See metrics.md for collecting performance metrics about Trickster.","title":"Other Ways to Monitor Health"},{"location":"influxdb/","text":"InfluxDB Support Trickster 1.0 provides support for accelerating InfluxDB queries that return time series data normally visualized on a dashboard. Acceleration works by using the Time Series Delta Proxy Cache to minimize the number and time range of queries to the upstream InfluxDB server. Scope of Support Trickster is tested with the built-in InfluxDB DataSource Plugin for Grafana v5.0.0. Trickster uses pre-compiled Regular Expression pattern matches on the incoming InfluxDB query to deconstruct its components, determine if it is cacheable and, if so, what elements are factored into the cache key derivation. We also determine what parts of the query are template-able (e.g., time >= $ts1 AND <= $ts2 ) based on the provided absolute values, in order to normalize the query before hashing the cache key. If you find query or response structures that are not yet supported, or providing inconsistent or unexpected results, we'd love for you to report those. We also always welcome any contributions around this functionality. The regular expression patterns we currently use will likely grow in complexity as support for more query patterns is added. Thus, we may need to find a more robust query parsing solution, and welcome any assistance with that as well. Trickster currently supports the following InfluxDB query patterns (case-insensitive), which align with queries generated by the InfluxDB Data Source Plugin for Grafana: SELECT field1 [, field2, field3...] FROM \"exampledb\".\"example_table\" WHERE (\"some_field\" = \"some_val\") AND $timeExpression GROUP BY time($duration) [, group2, group3...] The $timeExpression section must be in the format of time <operator1> $ts1 [AND <operator2> $ts2] Example $timeExpression strings: time >= now() time >= 1574699000000ms time >= 1574699000000ms AND time <= 1574699900000ms $duration must be in the format of <integer>ms such as 60s . The InfluxDB epoch HTTP request query parameter is currently required to be set to ms .","title":"InfluxDB Support"},{"location":"influxdb/#influxdb-support","text":"Trickster 1.0 provides support for accelerating InfluxDB queries that return time series data normally visualized on a dashboard. Acceleration works by using the Time Series Delta Proxy Cache to minimize the number and time range of queries to the upstream InfluxDB server.","title":"InfluxDB Support"},{"location":"influxdb/#scope-of-support","text":"Trickster is tested with the built-in InfluxDB DataSource Plugin for Grafana v5.0.0. Trickster uses pre-compiled Regular Expression pattern matches on the incoming InfluxDB query to deconstruct its components, determine if it is cacheable and, if so, what elements are factored into the cache key derivation. We also determine what parts of the query are template-able (e.g., time >= $ts1 AND <= $ts2 ) based on the provided absolute values, in order to normalize the query before hashing the cache key. If you find query or response structures that are not yet supported, or providing inconsistent or unexpected results, we'd love for you to report those. We also always welcome any contributions around this functionality. The regular expression patterns we currently use will likely grow in complexity as support for more query patterns is added. Thus, we may need to find a more robust query parsing solution, and welcome any assistance with that as well. Trickster currently supports the following InfluxDB query patterns (case-insensitive), which align with queries generated by the InfluxDB Data Source Plugin for Grafana: SELECT field1 [, field2, field3...] FROM \"exampledb\".\"example_table\" WHERE (\"some_field\" = \"some_val\") AND $timeExpression GROUP BY time($duration) [, group2, group3...] The $timeExpression section must be in the format of time <operator1> $ts1 [AND <operator2> $ts2] Example $timeExpression strings: time >= now() time >= 1574699000000ms time >= 1574699000000ms AND time <= 1574699900000ms $duration must be in the format of <integer>ms such as 60s . The InfluxDB epoch HTTP request query parameter is currently required to be set to ms .","title":"Scope of Support"},{"location":"metrics/","text":"Trickster Metrics Trickster exposes a Prometheus /metrics endpoint with a customizable listener port number (default is 8481). For more information on customizing the metrics configuration, see configuring.md . The following metrics are available for polling with any Trickster configuration: trickster_build_info (Gauge) - This gauge is always 1 when Trickster is running labels: goversion - the version of go under which the running Trickster binary was built revision - the commit ID on which the running Trickster binary was built version - semantic version of the running Trickster binary trickster_config_last_reload_successful (Gauge) - The value is 1 when true (the last config reload was successful) or 0 when false trickster_config_last_reload_success_time_seconds (Gauge) - Epoch timestamp of the last successful configuration reload trickster_frontend_requests_total (Counter) - Count of front end requests handled by Trickster labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_frontend_requests_duration_seconds (Histogram) - Histogram of front end request durations handled by Trickster labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_frontend_written_byte_total (Counter) - Count of bytes written in front end requests handled by Trickster labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_proxy_requests_total (Counter) - The total number of requests Trickster has handled. labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request cache_status - status codes are described here http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_proxy_points_total (Counter) - The total number of data points Trickster has handled. labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request cache_status - status codes are described here path - the Path portion of the requested URL trickster_proxy_request_duration_seconds (Histogram) - Time required to proxy a given Prometheus query. labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request cache_status - status codes are described here http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_proxy_max_connections (Gauge) - Trickster max number of allowed concurrent connections trickster_proxy_active_connections (Gauge) - Trickster number of concurrent connections trickster_proxy_requested_connections_total (Counter) - Trickster total number of connections requested by clients. trickster_proxy_accepted_connections_total (Counter) - Trickster total number of accepted client connections. trickster_proxy_closed_connections_total (Counter) - Trickster total number of administratively closed client connections. trickster_proxy_failed_connections_total (Counter) - Trickster total number of failed client connections. trickster_cache_operation_objects_total (Counter) - The total number of objects upon which the Trickster cache has operated. labels: cache_name - the name of the configured cache performing the operation$ provider - the type of the configured cache performing the operation operation - the name of the operation being performed (read, write, etc.) status - the result of the operation being performed trickster_cache_operation_bytes_total (Counter) - The total number of bytes upon which the Trickster cache has operated. labels: cache_name - the name of the configured cache performing the operation$ provider - the type of the configured cache performing the operation operation - the name of the operation being performed (read, write, etc.) status - the result of the operation being performed The following metrics are available only for Caches Types whose object lifecycle Trickster manages internally (Memory, Filesystem and bbolt): trickster_cache_events_total (Counter) - The total number of events that change the Trickster cache, such as retention policy evictions. labels: cache_name - the name of the configured cache experiencing the event$ provider - the type of the configured cache experiencing the event event - the name of the event being performed reason - the reason the event occurred trickster_cache_usage_objects (Gauge) - The current count of objects in the Trickster cache. labels: cache_name - the name of the configured cache$ provider - the type of the configured cache$ trickster_cache_usage_bytes (Gauge) - The current count of bytes in the Trickster cache. labels: cache_name - the name of the configured cache$ provider - the type of the configured cache$ trickster_cache_max_usage_objects (Gauge) - The maximum allowed size of the Trickster cache in objects. labels: cache_name - the name of the configured cache$ provider - the type of the configured cache trickster_cache_max_usage_bytes (Gauge) - The maximum allowed size of the Trickster cache in bytes. labels: cache_name - the name of the configured cache$ provider - the type of the configured cache In addition to these custom metrics, Trickster also exposes the standard Prometheus metrics that are part of the client_golang metrics instrumentation package, including memory and cpu utilization, etc.","title":"Trickster Metrics"},{"location":"metrics/#trickster-metrics","text":"Trickster exposes a Prometheus /metrics endpoint with a customizable listener port number (default is 8481). For more information on customizing the metrics configuration, see configuring.md . The following metrics are available for polling with any Trickster configuration: trickster_build_info (Gauge) - This gauge is always 1 when Trickster is running labels: goversion - the version of go under which the running Trickster binary was built revision - the commit ID on which the running Trickster binary was built version - semantic version of the running Trickster binary trickster_config_last_reload_successful (Gauge) - The value is 1 when true (the last config reload was successful) or 0 when false trickster_config_last_reload_success_time_seconds (Gauge) - Epoch timestamp of the last successful configuration reload trickster_frontend_requests_total (Counter) - Count of front end requests handled by Trickster labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_frontend_requests_duration_seconds (Histogram) - Histogram of front end request durations handled by Trickster labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_frontend_written_byte_total (Counter) - Count of bytes written in front end requests handled by Trickster labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_proxy_requests_total (Counter) - The total number of requests Trickster has handled. labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request cache_status - status codes are described here http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_proxy_points_total (Counter) - The total number of data points Trickster has handled. labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request cache_status - status codes are described here path - the Path portion of the requested URL trickster_proxy_request_duration_seconds (Histogram) - Time required to proxy a given Prometheus query. labels: origin_name - the name of the configured origin handling the proxy request provider - the type of the configured origin handling the proxy request method - the HTTP Method of the proxied request cache_status - status codes are described here http_status - The HTTP response code provided by the origin path - the Path portion of the requested URL trickster_proxy_max_connections (Gauge) - Trickster max number of allowed concurrent connections trickster_proxy_active_connections (Gauge) - Trickster number of concurrent connections trickster_proxy_requested_connections_total (Counter) - Trickster total number of connections requested by clients. trickster_proxy_accepted_connections_total (Counter) - Trickster total number of accepted client connections. trickster_proxy_closed_connections_total (Counter) - Trickster total number of administratively closed client connections. trickster_proxy_failed_connections_total (Counter) - Trickster total number of failed client connections. trickster_cache_operation_objects_total (Counter) - The total number of objects upon which the Trickster cache has operated. labels: cache_name - the name of the configured cache performing the operation$ provider - the type of the configured cache performing the operation operation - the name of the operation being performed (read, write, etc.) status - the result of the operation being performed trickster_cache_operation_bytes_total (Counter) - The total number of bytes upon which the Trickster cache has operated. labels: cache_name - the name of the configured cache performing the operation$ provider - the type of the configured cache performing the operation operation - the name of the operation being performed (read, write, etc.) status - the result of the operation being performed The following metrics are available only for Caches Types whose object lifecycle Trickster manages internally (Memory, Filesystem and bbolt): trickster_cache_events_total (Counter) - The total number of events that change the Trickster cache, such as retention policy evictions. labels: cache_name - the name of the configured cache experiencing the event$ provider - the type of the configured cache experiencing the event event - the name of the event being performed reason - the reason the event occurred trickster_cache_usage_objects (Gauge) - The current count of objects in the Trickster cache. labels: cache_name - the name of the configured cache$ provider - the type of the configured cache$ trickster_cache_usage_bytes (Gauge) - The current count of bytes in the Trickster cache. labels: cache_name - the name of the configured cache$ provider - the type of the configured cache$ trickster_cache_max_usage_objects (Gauge) - The maximum allowed size of the Trickster cache in objects. labels: cache_name - the name of the configured cache$ provider - the type of the configured cache trickster_cache_max_usage_bytes (Gauge) - The maximum allowed size of the Trickster cache in bytes. labels: cache_name - the name of the configured cache$ provider - the type of the configured cache In addition to these custom metrics, Trickster also exposes the standard Prometheus metrics that are part of the client_golang metrics instrumentation package, including memory and cpu utilization, etc.","title":"Trickster Metrics"},{"location":"multi-origin/","text":"Using Multiple-Origins with a single Trickster instance Trickster supports proxying to multiple origins by examining the inbound request and using a multiplexer to direct the proxied request to the correct upstream origin, in the same way that web servers support virtual hosting. Multi-origin does not equate to High Availability support; Trickster does not offer any kind of redundancy features. Using Multiple Origins simply means that a single Trickster instance can accelerate any number of unrelated upstream origins instead of requiring a Trickster instance per-origin. There are 2 ways to configure multi-origin support. HTTP Pathing DNS Aliasing Basic Usage To utilize Multiple Origins, you must craft a Trickster configuration file to be read when Trickster starts up - multi-origin is not supported with simply environment variables or command line arguments. The example.conf provides good documentation and commented sections demonstrating multi-origin. The config file should be placed in /etc/trickster/trickster.conf unless you specify a different path when starting Trickster with the -config command line argument. Each origin that your Trickster instance supports must be explicitly enumerated in the configuration file. Trickster does not support open proxying. Each origin is identified by an Origin Name, provided in the configuration section header for the origin ([origins.NAME]). For path-based routing configurations, the Origin Name can be simple words. For DNS Aliasing, the Origin Name must match an FQDN that resolves to your Trickster instance. Also for DNS Aliasing, enclose the FQDN in quotes in the origin config section header (e.g., [origins.'db.example.com'] ). Default Origin Whether proxying to one or more upstreams, Trickster has the concept of a \"default\" origin, which means it does not require a specific DNS hostname in the request, or a specific URL path, in order to proxy the request to a known origin. When a default origin is configured, if the inbound request does not match any mapped origins by path or FQDN, the request will automatically be mapped to the default origin. You are probably familiar with this behavior from when you first tried out Trickster with the using command line arguments. Here's an example: if you have Trickster configured with an origin named foo that proxies to http://foo/ and is configured as the default origin, then requesting http://trickster/image.jpg will initiate a proxy request to http://foo/image.jpg , without requiring the path be prefixed with /foo . But requesting to http://trickster/foo/image.jpg would also work. The default origin can be configured by setting is_default = true for the origin you have elected to make the default. Having a default origin is optional. In a single-origin configuration, Trickster will automatically set the sole origin as is_default = true unless you explicly set is_default = false in the configuration file. If you have multiple origins, and don't wish to have a default origin, you can just omit the value for all origins. If you set is_default = true for more than one origin, Trickster will exit with a fatal error on startup. Path-based Routing Configurations In this mode, Trickster will use a single FQDN but still map to multiple upstream origins. This is the simplest setup and requires the least amount of work. The client will indicate which origin is desired in URL Path for the request. Example Path-based Multi-Origin Configuration: [origins] # origin1 origin [origins.origin1] origin_url = 'http://prometheus.example.com:9090' provider = 'prometheus' cache_name = 'default' is_default = true # \"foo\" origin [origins.foo] origin_url = 'http://influxdb-foo.example.com:9090' provider = 'influxdb' cache_name = 'default' # \"bar\" origin [origins.bar] origin_url = 'http://prometheus-bar.example.com:9090' provider = 'prometheus' cache_name = 'default' Using HTTP Path as the Multi-Origin Indicator The client prefixes the Trickster request path with the Origin Name. This is the recommended method for integrating multi-origin support into Grafana. Example Client Request URLs: To Request from Origin foo : http://trickster.example.com:8480/foo/query?query=xxx To Request from Origin bar : http://trickster.example.com:8480/bar/query?query=xxx To Request from Origin origin1 as default: http://trickster.example.com:8480/query?query=xxx To Request from Origin origin1 (Method 2, with Origin Name): http://trickster.example.com:8480/origin1/query?query=xxx Configuring Grafana to request from origin foo via Trickster: DNS Alias Configuration In this mode, multiple DNS records point to a single Trickster instance. The FQDN used by the client to reach Trickster is mapped to specific origin configurations using the hosts list. In this mode, the URL Path is not considered during Origin Selection. Example DNS-based Origin Configuration: [origins] # origin1 origin [origins.origin1] hosts = [ '1.example.com', '2.example.com' ] # users can route to this origin via these FQDNs, or via `/origin1` origin_url = 'http://prometheus.example.com:9090' provider = 'prometheus' cache_name = 'default' is_default = true # \"foo\" origin [origins.foo] hosts = [ 'trickster-foo.example.com' ] # users can route to this origin via these FQDNs, or via `/foo` origin_url = 'http://prometheus-foo.example.com:9090' provider = 'prometheus' cache_name = 'default' # \"bar\" origin [origins.bar] hosts = [ 'trickster-bar.example.com' ] # users can route to this origin via these FQDNs, or via `/bar` origin_url = 'http://prometheus-bar.example.com:9090' provider = 'prometheus' cache_name = 'default' Example Client Request URLs: To Request from Origin foo : http://trickster-foo.example.com:8480/query?query=xxx To Request from Origin bar : http://trickster-bar.example.com:8480/query?query=xxx To Request from Origin origin1 as default: http://trickster.example.com:8480/query?query=xxx To Request from Origin origin1 (Method 2, via FQDN): http://origin1.example.com:8480/query?query=xxx Note: It is currently possible to specify the same FQDN in multiple origin configurations. You should not do this (obviously). A future enhancement will cause Trickster to exit fatally upon detection at startup. Disabling Path-based Routing for an Origin You may wish for an origin to be inaccessible via the /origin_name/ path, and only by Hostname or as the target of a rule . You can disable path routing by setting path_routing_disabled = true for the origin, as in this example, which requires the Request's Host header match 1.example.com or 2.example.com in order to be routed to the origin: [origins] # origin1 origin [origins.origin1] hosts = [ '1.example.com', '2.example.com' ] origin_url = 'http://prometheus.example.com:9090' provider = 'prometheus' cache_name = 'default' is_default = false path_routing_disabled = true","title":"Using Multiple-Origins with a single Trickster instance"},{"location":"multi-origin/#using-multiple-origins-with-a-single-trickster-instance","text":"Trickster supports proxying to multiple origins by examining the inbound request and using a multiplexer to direct the proxied request to the correct upstream origin, in the same way that web servers support virtual hosting. Multi-origin does not equate to High Availability support; Trickster does not offer any kind of redundancy features. Using Multiple Origins simply means that a single Trickster instance can accelerate any number of unrelated upstream origins instead of requiring a Trickster instance per-origin. There are 2 ways to configure multi-origin support. HTTP Pathing DNS Aliasing","title":"Using Multiple-Origins with a single Trickster instance"},{"location":"multi-origin/#basic-usage","text":"To utilize Multiple Origins, you must craft a Trickster configuration file to be read when Trickster starts up - multi-origin is not supported with simply environment variables or command line arguments. The example.conf provides good documentation and commented sections demonstrating multi-origin. The config file should be placed in /etc/trickster/trickster.conf unless you specify a different path when starting Trickster with the -config command line argument. Each origin that your Trickster instance supports must be explicitly enumerated in the configuration file. Trickster does not support open proxying. Each origin is identified by an Origin Name, provided in the configuration section header for the origin ([origins.NAME]). For path-based routing configurations, the Origin Name can be simple words. For DNS Aliasing, the Origin Name must match an FQDN that resolves to your Trickster instance. Also for DNS Aliasing, enclose the FQDN in quotes in the origin config section header (e.g., [origins.'db.example.com'] ).","title":"Basic Usage"},{"location":"multi-origin/#default-origin","text":"Whether proxying to one or more upstreams, Trickster has the concept of a \"default\" origin, which means it does not require a specific DNS hostname in the request, or a specific URL path, in order to proxy the request to a known origin. When a default origin is configured, if the inbound request does not match any mapped origins by path or FQDN, the request will automatically be mapped to the default origin. You are probably familiar with this behavior from when you first tried out Trickster with the using command line arguments. Here's an example: if you have Trickster configured with an origin named foo that proxies to http://foo/ and is configured as the default origin, then requesting http://trickster/image.jpg will initiate a proxy request to http://foo/image.jpg , without requiring the path be prefixed with /foo . But requesting to http://trickster/foo/image.jpg would also work. The default origin can be configured by setting is_default = true for the origin you have elected to make the default. Having a default origin is optional. In a single-origin configuration, Trickster will automatically set the sole origin as is_default = true unless you explicly set is_default = false in the configuration file. If you have multiple origins, and don't wish to have a default origin, you can just omit the value for all origins. If you set is_default = true for more than one origin, Trickster will exit with a fatal error on startup.","title":"Default Origin"},{"location":"multi-origin/#path-based-routing-configurations","text":"In this mode, Trickster will use a single FQDN but still map to multiple upstream origins. This is the simplest setup and requires the least amount of work. The client will indicate which origin is desired in URL Path for the request. Example Path-based Multi-Origin Configuration: [origins] # origin1 origin [origins.origin1] origin_url = 'http://prometheus.example.com:9090' provider = 'prometheus' cache_name = 'default' is_default = true # \"foo\" origin [origins.foo] origin_url = 'http://influxdb-foo.example.com:9090' provider = 'influxdb' cache_name = 'default' # \"bar\" origin [origins.bar] origin_url = 'http://prometheus-bar.example.com:9090' provider = 'prometheus' cache_name = 'default'","title":"Path-based Routing Configurations"},{"location":"multi-origin/#using-http-path-as-the-multi-origin-indicator","text":"The client prefixes the Trickster request path with the Origin Name. This is the recommended method for integrating multi-origin support into Grafana. Example Client Request URLs: To Request from Origin foo : http://trickster.example.com:8480/foo/query?query=xxx To Request from Origin bar : http://trickster.example.com:8480/bar/query?query=xxx To Request from Origin origin1 as default: http://trickster.example.com:8480/query?query=xxx To Request from Origin origin1 (Method 2, with Origin Name): http://trickster.example.com:8480/origin1/query?query=xxx Configuring Grafana to request from origin foo via Trickster:","title":"Using HTTP Path as the Multi-Origin Indicator"},{"location":"multi-origin/#dns-alias-configuration","text":"In this mode, multiple DNS records point to a single Trickster instance. The FQDN used by the client to reach Trickster is mapped to specific origin configurations using the hosts list. In this mode, the URL Path is not considered during Origin Selection. Example DNS-based Origin Configuration: [origins] # origin1 origin [origins.origin1] hosts = [ '1.example.com', '2.example.com' ] # users can route to this origin via these FQDNs, or via `/origin1` origin_url = 'http://prometheus.example.com:9090' provider = 'prometheus' cache_name = 'default' is_default = true # \"foo\" origin [origins.foo] hosts = [ 'trickster-foo.example.com' ] # users can route to this origin via these FQDNs, or via `/foo` origin_url = 'http://prometheus-foo.example.com:9090' provider = 'prometheus' cache_name = 'default' # \"bar\" origin [origins.bar] hosts = [ 'trickster-bar.example.com' ] # users can route to this origin via these FQDNs, or via `/bar` origin_url = 'http://prometheus-bar.example.com:9090' provider = 'prometheus' cache_name = 'default' Example Client Request URLs: To Request from Origin foo : http://trickster-foo.example.com:8480/query?query=xxx To Request from Origin bar : http://trickster-bar.example.com:8480/query?query=xxx To Request from Origin origin1 as default: http://trickster.example.com:8480/query?query=xxx To Request from Origin origin1 (Method 2, via FQDN): http://origin1.example.com:8480/query?query=xxx Note: It is currently possible to specify the same FQDN in multiple origin configurations. You should not do this (obviously). A future enhancement will cause Trickster to exit fatally upon detection at startup.","title":"DNS Alias Configuration"},{"location":"multi-origin/#disabling-path-based-routing-for-an-origin","text":"You may wish for an origin to be inaccessible via the /origin_name/ path, and only by Hostname or as the target of a rule . You can disable path routing by setting path_routing_disabled = true for the origin, as in this example, which requires the Request's Host header match 1.example.com or 2.example.com in order to be routed to the origin: [origins] # origin1 origin [origins.origin1] hosts = [ '1.example.com', '2.example.com' ] origin_url = 'http://prometheus.example.com:9090' provider = 'prometheus' cache_name = 'default' is_default = false path_routing_disabled = true","title":"Disabling Path-based Routing for an Origin"},{"location":"negative-caching/","text":"Negative Caching Negative Caching means to cache undesired HTTP responses for a very short period of time, in order to prevent overwhelming a system that would otherwise scale normally when desired, cacheable HTTP responses are being returned. For example, Trickster can be configured to cache 404 Not Found or 500 Internal Server Error responses for a short period of time, to ensure that a thundering herd of HTTP requests for a non-existent object, or unexpected downtime of a citical service, do not create an i/o bottleneck in your application pipeline. Trickster supports negative caching of any status code >= 300 and < 600, on a per-Origin basis. In your Trickster configuration file, associate the desired Negative Cache Map to the desired Origin config. See the example.conf , or refer to the snippet below for more information. The Negative Cache Map must be an all-inclusive list of explicit status codes; there is currently no wildcard or status code range support for Negative Caching entries. By default, the Negative Cache Map is empty for all origin configs. The Negative Cache only applies to Cacheable Objects, and does not apply to Proxy-Only configurations. For any response code handled by the Negative Cache, the response object's effective cache TTL is explicitly overridden to the value of that code's Negative Cache TTL, regardless of any response headers provided by the Origin concerning cacheability. All response headers are left in-tact and unmodified by Trickster's Negative Cache, such that Negative Caching is transparent to the client. The X-Trickster-Result response header will indicate a response was served from the Negative Cache by providing a cache status of nchit . You can define multiple negative cache configurations, and reference them by name in the origin config. By Default, an origin will use the 'default' Negative Cache config, which, by default is empty. The default can be easily populated in the config file, and additionl configs can easily be added, as demonstrated below. Example Negative Caching Config [negative_caches] [negative_caches.default] 404 = 3 # cache 404 responses for 3 seconds [negative_caches.foo] 404 = 3 500 = 5 502 = 5 [origins] [origins.default] provider = 'rpc' # by default will assume negative_cache_name = 'default' [origins.another] provider = 'rpc' negative_cache_name = 'foo'","title":"Negative Caching"},{"location":"negative-caching/#negative-caching","text":"Negative Caching means to cache undesired HTTP responses for a very short period of time, in order to prevent overwhelming a system that would otherwise scale normally when desired, cacheable HTTP responses are being returned. For example, Trickster can be configured to cache 404 Not Found or 500 Internal Server Error responses for a short period of time, to ensure that a thundering herd of HTTP requests for a non-existent object, or unexpected downtime of a citical service, do not create an i/o bottleneck in your application pipeline. Trickster supports negative caching of any status code >= 300 and < 600, on a per-Origin basis. In your Trickster configuration file, associate the desired Negative Cache Map to the desired Origin config. See the example.conf , or refer to the snippet below for more information. The Negative Cache Map must be an all-inclusive list of explicit status codes; there is currently no wildcard or status code range support for Negative Caching entries. By default, the Negative Cache Map is empty for all origin configs. The Negative Cache only applies to Cacheable Objects, and does not apply to Proxy-Only configurations. For any response code handled by the Negative Cache, the response object's effective cache TTL is explicitly overridden to the value of that code's Negative Cache TTL, regardless of any response headers provided by the Origin concerning cacheability. All response headers are left in-tact and unmodified by Trickster's Negative Cache, such that Negative Caching is transparent to the client. The X-Trickster-Result response header will indicate a response was served from the Negative Cache by providing a cache status of nchit . You can define multiple negative cache configurations, and reference them by name in the origin config. By Default, an origin will use the 'default' Negative Cache config, which, by default is empty. The default can be easily populated in the config file, and additionl configs can easily be added, as demonstrated below.","title":"Negative Caching"},{"location":"negative-caching/#example-negative-caching-config","text":"[negative_caches] [negative_caches.default] 404 = 3 # cache 404 responses for 3 seconds [negative_caches.foo] 404 = 3 500 = 5 502 = 5 [origins] [origins.default] provider = 'rpc' # by default will assume negative_cache_name = 'default' [origins.another] provider = 'rpc' negative_cache_name = 'foo'","title":"Example Negative Caching Config"},{"location":"new-changed-1.1/","text":"Trickster 1.1 What's Improved 1.1 continues to improve the Trickster project, with a ton of new features, bug fixes, and optimizations. Here's the quick rundown of what's new and improved: Our GitHub project is relocated from Comcast/trickster to tricksterproxy/trickster Our Docker Hub organization name is changed from tricksterio to tricksterproxy Helm charts are relocated to tricksterproxy/helm-charts and published at https://helm.tricksterproxy.io All project references and package imports updated per the project relocation All project packages are moved from ./internal to ./pkg to facilitate importation by other projects Trickster releases are now published using fully-automated, secure GitHub Actions New trickster-demo Docker Compose reference environment for anyone to easily see Trickster in action Added Windows support; win64 binaries are now included in Release We now use a single, all-platforms release tarball, complete with bin docs and conf directories Trickster-specific default listener ports: 8480 (http), 8481 (metrics), 8483 (tls), 8484 (reload) In-process config reloading via HUP or optional http listener endpoint Added -validate-config command line flag Customizable pprof debugging server configurations Updated to OpenTelemetry 0.6.0, streamlined Tracing configs, added Zipkin exporter support Updated Named Locks package to support RWMutex for concurrent cached object reads New Rules Engine for custom request handling and rewriting HTTP 2.0 Support systemd service file ( trickster.service ) is relocated from ./cmd/trickster/conf/ to ./deploy/systemd/ rangesim package has been rebranded as mockster , and moved to its own project , with its own docker image using port 8482 Fully support acceleration of HTTP POST requests to Prometheus and InfluxDB endpoints Updated dependencies to Go 1.14.3, Alpine 3.12, InfluxDB 1.8.0 Installing You can build the 1.1 binary from the main branch, download binaries from the Releases page, or use the tricksterproxy/trickster:1.1 Docker image tag in containerized environments. Helm Charts version 1.5.0 is the chart release associated with Trickster v1.1. Breaking Changes from 1.0 Port Changes If you rely on default settings in your deployment, rather than setting explicit values, be prepared to make adjustments to accommodate Trickster's new default ports. We encourage you to adjust your Trickster deployments to explicitly use the new default ports. Distributed Tracing Configuration The [tracing] section of the Trickster TOML config specification has changed slightly, and is incompatible with a v1.0 config. If you use the tracing feature, be sure to check the example.conf and adjust yours accordingly. Known Issues Zipkin Zipkin implementation currently works with the OpenZipkin Collector, but not Jaeger Collector's Zipkin-compatible endpoints","title":"Trickster 1.1"},{"location":"new-changed-1.1/#trickster-11","text":"","title":"Trickster 1.1"},{"location":"new-changed-1.1/#whats-improved","text":"1.1 continues to improve the Trickster project, with a ton of new features, bug fixes, and optimizations. Here's the quick rundown of what's new and improved: Our GitHub project is relocated from Comcast/trickster to tricksterproxy/trickster Our Docker Hub organization name is changed from tricksterio to tricksterproxy Helm charts are relocated to tricksterproxy/helm-charts and published at https://helm.tricksterproxy.io All project references and package imports updated per the project relocation All project packages are moved from ./internal to ./pkg to facilitate importation by other projects Trickster releases are now published using fully-automated, secure GitHub Actions New trickster-demo Docker Compose reference environment for anyone to easily see Trickster in action Added Windows support; win64 binaries are now included in Release We now use a single, all-platforms release tarball, complete with bin docs and conf directories Trickster-specific default listener ports: 8480 (http), 8481 (metrics), 8483 (tls), 8484 (reload) In-process config reloading via HUP or optional http listener endpoint Added -validate-config command line flag Customizable pprof debugging server configurations Updated to OpenTelemetry 0.6.0, streamlined Tracing configs, added Zipkin exporter support Updated Named Locks package to support RWMutex for concurrent cached object reads New Rules Engine for custom request handling and rewriting HTTP 2.0 Support systemd service file ( trickster.service ) is relocated from ./cmd/trickster/conf/ to ./deploy/systemd/ rangesim package has been rebranded as mockster , and moved to its own project , with its own docker image using port 8482 Fully support acceleration of HTTP POST requests to Prometheus and InfluxDB endpoints Updated dependencies to Go 1.14.3, Alpine 3.12, InfluxDB 1.8.0","title":"What's Improved"},{"location":"new-changed-1.1/#installing","text":"You can build the 1.1 binary from the main branch, download binaries from the Releases page, or use the tricksterproxy/trickster:1.1 Docker image tag in containerized environments. Helm Charts version 1.5.0 is the chart release associated with Trickster v1.1.","title":"Installing"},{"location":"new-changed-1.1/#breaking-changes-from-10","text":"","title":"Breaking Changes from 1.0"},{"location":"new-changed-1.1/#port-changes","text":"If you rely on default settings in your deployment, rather than setting explicit values, be prepared to make adjustments to accommodate Trickster's new default ports. We encourage you to adjust your Trickster deployments to explicitly use the new default ports.","title":"Port Changes"},{"location":"new-changed-1.1/#distributed-tracing-configuration","text":"The [tracing] section of the Trickster TOML config specification has changed slightly, and is incompatible with a v1.0 config. If you use the tracing feature, be sure to check the example.conf and adjust yours accordingly.","title":"Distributed Tracing Configuration"},{"location":"new-changed-1.1/#known-issues","text":"","title":"Known Issues"},{"location":"new-changed-1.1/#zipkin","text":"Zipkin implementation currently works with the OpenZipkin Collector, but not Jaeger Collector's Zipkin-compatible endpoints","title":"Zipkin"},{"location":"paths/","text":"Customizing HTTP Path Behavior Trickster supports, via configuration, customizing the upstream request and downstream response behavior on a per-Path, per-Origin basis, by providing a paths configuration section for each origin configuration. Here are the basic capabilities for customizing Path behavior: Modify client request headers prior to contacting the origin while proxying Modify origin response headers prior to processing the response object in Trickster and delivering to the client Modify the response code and body Limit the scope of a path by HTTP Method Select the HTTP Handler for the path ( proxy , proxycache or a published origin-type-specific handler) Select which HTTP Headers, URL Parameters and other client request characteristics will be used to derive the Cache Key under which Trickster stores the object. Disable Metrics Reporting for the path Path Matching Scope Paths are matchable as exact or prefix The default match is exact , meaning the client's requested URL Path must be an exact match to the configured path in order to match and be handled by a given Path Config. For example a request to /foo/bar will not match an exact Path Config for /foo . A prefix match will match any client-requested path to the Path Config with the longest prefix match. A prefix match Path Config to /foo will match /foo/bar as well as /foobar and /food . A basic string match is used to evaluate the incoming URL path, so it is recommended to consider finishing paths with a trailing / , like /foo/ in Path Configurations, if needed to avoid any unintentional matches. Method Matching Scope The methods section of a Path Config takes a string array of HTTP Methods that are routed through this Path Config. You can provide [ '*' ] to route all methods for this path. Suggested Use Cases Redirect a path by configuring Trickster to respond with a 302 response code and a Location header Issue a blanket 401 Unauthorized code and custom response body to all requests for a given path. Adjust Cache Control headers in either direction Affix an Authorization header to requests proxied out by Trickster. Control which paths are cached by Trickster, and which ones are simply proxied. Request Rewriters You can configure paths send inbound requests through a request rewriter that can modify any aspect of the inbound request (method, url, headers, etc.), before being processed by the path route. This means, when the path route inspects the request, it will have already been modified by the rewriter. Provide a rewriter with the req_rewriter_name config. It must map to a named/configured request rewriter (see request rewriters for more info). Note, you can also send requests through a rewriter at the origin level. If both are configured, origin-level rewriters are executed before path rewriters are. [request_rewriters] # this example request rewriter adds an additional header to the request [request_rewriters.example] instructions = [ [\"header\", \"set\", \"Example-Header-Name\", \"Example Value\"] ] [origins] [origins.default] provider = 'rpc' origin_url = 'http://example.com' [origins.default.paths] [origins.default.paths.root] path = '/' req_rewriter_name = 'example' Header and Query Parameter Behavior In addition to running the request through a named rewriter, it is currently possible to make similar changes to the request with legacy path features that are described in this section. Note that these are likely to be deprecated in a future Trickster release, in favor of the more versatile named rewriters described above, which accomplish the same thing. Currently, if both a named rewriter and legacy path-based rewriting configs are defined for a given path, the named rewriter will be executed first. Basics You can specify request query parameters, as well as request and response headers, to be Set, Appended or Removed. Setting To Set a header or parameter means to insert if non-existent, or fully replace if pre-existing. To set a header, provide the header name and value you wish to set in the Path Config request_params , request_headers or response_headers sections, in the format of 'Header-or-Parameter-Name' = 'Value' . As an example, if the client request provides a Cache-Control: no-store header, a Path Config with a header 'set' directive for 'Cache-Control' = 'no-transform' will replace the no-store entirely with a no-transform ; client requests that have no Cache-Control header that are routed through this Path will have the Trickster-configured header injected outright. The same logic applies to query parameters. Appending Appending a means inserting the header or parameter if it doesn't exist, or appending the configured value(s) into a pre-existing header with the given name. To indicate an append behavior (as opposed to set), prefix the header or parameter name with a '+' in the Path Config. Example: if the client request provides a token=SomeHash parameter and the Path Config includes the parameter '+token' = 'ProxyHash' , the effective parameter when forwarding the request to the origin will be token=SomeHash&token=ProxyHash . Removing Removing a header or parameter means to strip it from the HTTP Request or Response when present. To do so, prefix the header/parameter name with '-', for example, -Cache-control: none . When removing headers, a value is required to be provided in order to conform to TOML specification; this value, however, is innefectual. Note that there is currently no ability to remove a specific header value from a specific header - only the entire removal header. Consider setting the header value outright as described above, to strip any unwanted values. Response Header Timing Response Header injections occur as the object is received from the origin and before Trickster handles the object, meaning any caching response headers injected by Trickster will also be used by Trickster immediately to handle caching policies internally. This allows users to override cache controls from upstream systems if necessary to alter the actual caching behavior inside of Trickster. For example, InfluxDB sends down a Cache-Control: No-Cache header, which is fine for the user's browser, but Trickster needs to ignore this header in order to accelerate InfluxDB; so the default Path Configs for InfluxDB actually removes this header. Cache Key Components By default, Trickster will use the HTTP Method, URL Path and any Authorization header to derive its Cache Key. In a Path Config, you may specify any additional HTTP headers and URL Parameters to be used for cache key derivation, as well as information in the Request Body. Using Request Body Fields in Cache Key Hashing Trickster supports the parsing of the HTTP Request body for the purpose of deriving the Cache Key for a cacheable object. Note that body parsing requires reading the entire request body into memory and parsing it before operating on the object. This will result in slightly higher resource utilization and latency, depending upon the size of the client request body. Body parsing is supported when the request's HTTP method is POST , PUT or PATCH , and the request Content-Type is either application/x-www-form-urlencoded , multipart/form-data , or application/json . In a Path Config, provide the cache_key_form_fields setting with a list of form field names to include when hashing the cache key. Trickster supports parsing of the Request body as a JSON document, including documents that are multiple levels deep, using a basic pathing convention of forward slashes, to indicate the path to a field that should be included in the cache key. Take the following JSON document: { \"requestType\": \"query\", \"query\": { \"table\": \"movies\", \"fields\": \"eidr,title\", \"filter\": \"year=1979\" } } To include the requestType , table , fields , and filter fields from this document when hashing the cache key, you can provide the following setting in a Path Configuration: cache_key_form_fields = [ 'requestType', 'query/table', 'query/fields', 'query/filter' ] Example Reverse Proxy Cache Config with Path Customizations [origins] [origins.default] provider = 'rpc' [origins.default.paths] # root path '/'. Paths must be uniquely named but the # name is otherwise unimportant [origins.default.paths.root] path = '/' # each path must be unique for the origin methods = [ '*' ] # All HTTP methods applicable to this config match_type = 'prefix' # matches any path under '/' handler = 'proxy' # proxy only, no caching (this is the default) # modify the query parameters en route to the origin [origins.default.paths.root.request_params] 'authToken' = 'secret string' # When a user requests a path matching this route, Trickster will # inject these headers into the request before contacting the Origin [origins.default.paths.root.request_headers] 'Cache-Control' = 'No-Transform' # Due to hyphens, quote the key name # inject these headers into the response from the Origin # before replying to the client [origins.default.paths.root.response_headers] 'Expires' = '-1' [origins.default.paths.images] path = '/images/' methods = [ 'GET', 'HEAD' ] handler = 'proxycache' # Trickster will cache the images directory match_type = 'prefix' [origins.default.paths.images.response_headers] 'Cache-Control' = 'max-age=2592000' # cache for 30 days # but only cache this rotating image for 30 seconds [origins.default.paths.images_rotating] path = '/images/rotating.jpg' methods = [ 'GET' ] handler = 'proxycache' match_type = 'exact' [origins.default.paths.images_rotating.response_headers] 'Cache-Control' = 'max-age=30' '-Expires' = ' # redirect this sunsetted feature to a discontinued message [origins.default.paths.redirect] path = '/blog' methods = [ '*' ] handler = 'localresponse' match_type = 'prefix' response_code = 302 [origins.default.paths.redirect.response_headers] Location = '/discontinued' # cache this API endpoint, keying on the query parameter [origins.default.paths.api] path = '/api/' methods = [ 'GET', 'HEAD' ] handler = 'proxycache' match_type = 'prefix' cache_key_params = [ 'query' ] # same API endpoint, different HTTP methods to route against [origins.default.paths.api-deny] path = '/api/' methods = [ 'POST', 'PUT', 'PATCH', 'DELETE', 'OPTIONS', 'CONNECT' ] handler = 'localresponse' match_type = 'prefix' response_code = 401 response_body = 'this is a read-only api endpoint' # cache the query endpoint, permitting GET or POST [origins.default.paths.api-query] path = '/api/query/' methods = [ 'GET', 'HEAD', 'POST' ] handler = 'proxycache' match_type = 'prefix' cache_key_params = [ 'query' ] # for GET / HEAD cache_key_form_fields = [ 'query' ] # for POST Modifying Behavior of Time Series Origin Types Each of the Time Series Origin Types supported in Trickster comes with its own custom handlers and pre-defined Path Configs that are registered with the HTTP Router when Trickster starts up. For example, when Trickster is configured to accelerate Prometheus, pre-defined Path Configs are registered to control how requests to /api/v1/query work differently from requests to /api/v1/query_range . For example, the /ap1/v1/query Path Config uses the query and time URL query qarameters when creating the cache key, and is routed through the Object Proxy Cache; while the /api/v1/query_range Path Config uses the query , start , end and step parameters, and is routed through the Time Series Delta Proxy Cache. In the Trickster config file, you can add your own Path Configs to your time series origin, as well override individual settings for any of the pre-defined Path Configs, and those custom settings will be applied at startup. To know what configs you'd like to add or modify, take a look at the Trickster source code and examine the pre-definitions for the selected Origin Type. Each supported Origin Type's handlers and default Path Configs can be viewed under /internal/proxy/origins/<origin_type>/routes.go . These files are in a standard format that are quite human-readable, even for a non-coder, so don't be too intimidated. If you can understand Path Configs as TOML, you can understand them as Go code. Examples of customizing Path Configs for Origin Types with Pre-Definitions: [origins] [origins.default] provider = 'prometheus' [origins.default.paths] # route /api/v1/label* (including /labels/*) # through Proxy instead of ProxyCache as pre-defined [origins.default.paths.label] path = '/api/v1/label' methods = [ 'GET' ] match_type = 'prefix' handler = 'proxy' # route fictional new /api/v1/coffee to ProxyCache [origins.default.paths.series_range] path = '/api/v1/coffee' methods = [ 'GET' ] match_type = 'prefix' handler = 'proxycache' cache_key_params = [ 'beans' ] # block /api/v1/admin/ from being reachable via Trickster [origins.default.paths.admin] path = '/api/v1/admin/' methods = [ 'GET', 'POST', 'PUT', 'HEAD', 'DELETE', 'OPTIONS' ] match_type = 'prefix' handler = 'localresponse' response_code = 401 response_body = 'No soup for you!' no_metrics = true","title":"Customizing HTTP Path Behavior"},{"location":"paths/#customizing-http-path-behavior","text":"Trickster supports, via configuration, customizing the upstream request and downstream response behavior on a per-Path, per-Origin basis, by providing a paths configuration section for each origin configuration. Here are the basic capabilities for customizing Path behavior: Modify client request headers prior to contacting the origin while proxying Modify origin response headers prior to processing the response object in Trickster and delivering to the client Modify the response code and body Limit the scope of a path by HTTP Method Select the HTTP Handler for the path ( proxy , proxycache or a published origin-type-specific handler) Select which HTTP Headers, URL Parameters and other client request characteristics will be used to derive the Cache Key under which Trickster stores the object. Disable Metrics Reporting for the path","title":"Customizing HTTP Path Behavior"},{"location":"paths/#path-matching-scope","text":"Paths are matchable as exact or prefix The default match is exact , meaning the client's requested URL Path must be an exact match to the configured path in order to match and be handled by a given Path Config. For example a request to /foo/bar will not match an exact Path Config for /foo . A prefix match will match any client-requested path to the Path Config with the longest prefix match. A prefix match Path Config to /foo will match /foo/bar as well as /foobar and /food . A basic string match is used to evaluate the incoming URL path, so it is recommended to consider finishing paths with a trailing / , like /foo/ in Path Configurations, if needed to avoid any unintentional matches.","title":"Path Matching Scope"},{"location":"paths/#method-matching-scope","text":"The methods section of a Path Config takes a string array of HTTP Methods that are routed through this Path Config. You can provide [ '*' ] to route all methods for this path.","title":"Method Matching Scope"},{"location":"paths/#suggested-use-cases","text":"Redirect a path by configuring Trickster to respond with a 302 response code and a Location header Issue a blanket 401 Unauthorized code and custom response body to all requests for a given path. Adjust Cache Control headers in either direction Affix an Authorization header to requests proxied out by Trickster. Control which paths are cached by Trickster, and which ones are simply proxied.","title":"Suggested Use Cases"},{"location":"paths/#request-rewriters","text":"You can configure paths send inbound requests through a request rewriter that can modify any aspect of the inbound request (method, url, headers, etc.), before being processed by the path route. This means, when the path route inspects the request, it will have already been modified by the rewriter. Provide a rewriter with the req_rewriter_name config. It must map to a named/configured request rewriter (see request rewriters for more info). Note, you can also send requests through a rewriter at the origin level. If both are configured, origin-level rewriters are executed before path rewriters are. [request_rewriters] # this example request rewriter adds an additional header to the request [request_rewriters.example] instructions = [ [\"header\", \"set\", \"Example-Header-Name\", \"Example Value\"] ] [origins] [origins.default] provider = 'rpc' origin_url = 'http://example.com' [origins.default.paths] [origins.default.paths.root] path = '/' req_rewriter_name = 'example'","title":"Request Rewriters"},{"location":"paths/#header-and-query-parameter-behavior","text":"In addition to running the request through a named rewriter, it is currently possible to make similar changes to the request with legacy path features that are described in this section. Note that these are likely to be deprecated in a future Trickster release, in favor of the more versatile named rewriters described above, which accomplish the same thing. Currently, if both a named rewriter and legacy path-based rewriting configs are defined for a given path, the named rewriter will be executed first.","title":"Header and Query Parameter Behavior"},{"location":"paths/#basics","text":"You can specify request query parameters, as well as request and response headers, to be Set, Appended or Removed.","title":"Basics"},{"location":"paths/#setting","text":"To Set a header or parameter means to insert if non-existent, or fully replace if pre-existing. To set a header, provide the header name and value you wish to set in the Path Config request_params , request_headers or response_headers sections, in the format of 'Header-or-Parameter-Name' = 'Value' . As an example, if the client request provides a Cache-Control: no-store header, a Path Config with a header 'set' directive for 'Cache-Control' = 'no-transform' will replace the no-store entirely with a no-transform ; client requests that have no Cache-Control header that are routed through this Path will have the Trickster-configured header injected outright. The same logic applies to query parameters.","title":"Setting"},{"location":"paths/#appending","text":"Appending a means inserting the header or parameter if it doesn't exist, or appending the configured value(s) into a pre-existing header with the given name. To indicate an append behavior (as opposed to set), prefix the header or parameter name with a '+' in the Path Config. Example: if the client request provides a token=SomeHash parameter and the Path Config includes the parameter '+token' = 'ProxyHash' , the effective parameter when forwarding the request to the origin will be token=SomeHash&token=ProxyHash .","title":"Appending"},{"location":"paths/#removing","text":"Removing a header or parameter means to strip it from the HTTP Request or Response when present. To do so, prefix the header/parameter name with '-', for example, -Cache-control: none . When removing headers, a value is required to be provided in order to conform to TOML specification; this value, however, is innefectual. Note that there is currently no ability to remove a specific header value from a specific header - only the entire removal header. Consider setting the header value outright as described above, to strip any unwanted values.","title":"Removing"},{"location":"paths/#response-header-timing","text":"Response Header injections occur as the object is received from the origin and before Trickster handles the object, meaning any caching response headers injected by Trickster will also be used by Trickster immediately to handle caching policies internally. This allows users to override cache controls from upstream systems if necessary to alter the actual caching behavior inside of Trickster. For example, InfluxDB sends down a Cache-Control: No-Cache header, which is fine for the user's browser, but Trickster needs to ignore this header in order to accelerate InfluxDB; so the default Path Configs for InfluxDB actually removes this header.","title":"Response Header Timing"},{"location":"paths/#cache-key-components","text":"By default, Trickster will use the HTTP Method, URL Path and any Authorization header to derive its Cache Key. In a Path Config, you may specify any additional HTTP headers and URL Parameters to be used for cache key derivation, as well as information in the Request Body.","title":"Cache Key Components"},{"location":"paths/#using-request-body-fields-in-cache-key-hashing","text":"Trickster supports the parsing of the HTTP Request body for the purpose of deriving the Cache Key for a cacheable object. Note that body parsing requires reading the entire request body into memory and parsing it before operating on the object. This will result in slightly higher resource utilization and latency, depending upon the size of the client request body. Body parsing is supported when the request's HTTP method is POST , PUT or PATCH , and the request Content-Type is either application/x-www-form-urlencoded , multipart/form-data , or application/json . In a Path Config, provide the cache_key_form_fields setting with a list of form field names to include when hashing the cache key. Trickster supports parsing of the Request body as a JSON document, including documents that are multiple levels deep, using a basic pathing convention of forward slashes, to indicate the path to a field that should be included in the cache key. Take the following JSON document: { \"requestType\": \"query\", \"query\": { \"table\": \"movies\", \"fields\": \"eidr,title\", \"filter\": \"year=1979\" } } To include the requestType , table , fields , and filter fields from this document when hashing the cache key, you can provide the following setting in a Path Configuration: cache_key_form_fields = [ 'requestType', 'query/table', 'query/fields', 'query/filter' ]","title":"Using Request Body Fields in Cache Key Hashing"},{"location":"paths/#example-reverse-proxy-cache-config-with-path-customizations","text":"[origins] [origins.default] provider = 'rpc' [origins.default.paths] # root path '/'. Paths must be uniquely named but the # name is otherwise unimportant [origins.default.paths.root] path = '/' # each path must be unique for the origin methods = [ '*' ] # All HTTP methods applicable to this config match_type = 'prefix' # matches any path under '/' handler = 'proxy' # proxy only, no caching (this is the default) # modify the query parameters en route to the origin [origins.default.paths.root.request_params] 'authToken' = 'secret string' # When a user requests a path matching this route, Trickster will # inject these headers into the request before contacting the Origin [origins.default.paths.root.request_headers] 'Cache-Control' = 'No-Transform' # Due to hyphens, quote the key name # inject these headers into the response from the Origin # before replying to the client [origins.default.paths.root.response_headers] 'Expires' = '-1' [origins.default.paths.images] path = '/images/' methods = [ 'GET', 'HEAD' ] handler = 'proxycache' # Trickster will cache the images directory match_type = 'prefix' [origins.default.paths.images.response_headers] 'Cache-Control' = 'max-age=2592000' # cache for 30 days # but only cache this rotating image for 30 seconds [origins.default.paths.images_rotating] path = '/images/rotating.jpg' methods = [ 'GET' ] handler = 'proxycache' match_type = 'exact' [origins.default.paths.images_rotating.response_headers] 'Cache-Control' = 'max-age=30' '-Expires' = ' # redirect this sunsetted feature to a discontinued message [origins.default.paths.redirect] path = '/blog' methods = [ '*' ] handler = 'localresponse' match_type = 'prefix' response_code = 302 [origins.default.paths.redirect.response_headers] Location = '/discontinued' # cache this API endpoint, keying on the query parameter [origins.default.paths.api] path = '/api/' methods = [ 'GET', 'HEAD' ] handler = 'proxycache' match_type = 'prefix' cache_key_params = [ 'query' ] # same API endpoint, different HTTP methods to route against [origins.default.paths.api-deny] path = '/api/' methods = [ 'POST', 'PUT', 'PATCH', 'DELETE', 'OPTIONS', 'CONNECT' ] handler = 'localresponse' match_type = 'prefix' response_code = 401 response_body = 'this is a read-only api endpoint' # cache the query endpoint, permitting GET or POST [origins.default.paths.api-query] path = '/api/query/' methods = [ 'GET', 'HEAD', 'POST' ] handler = 'proxycache' match_type = 'prefix' cache_key_params = [ 'query' ] # for GET / HEAD cache_key_form_fields = [ 'query' ] # for POST","title":"Example Reverse Proxy Cache Config with Path Customizations"},{"location":"paths/#modifying-behavior-of-time-series-origin-types","text":"Each of the Time Series Origin Types supported in Trickster comes with its own custom handlers and pre-defined Path Configs that are registered with the HTTP Router when Trickster starts up. For example, when Trickster is configured to accelerate Prometheus, pre-defined Path Configs are registered to control how requests to /api/v1/query work differently from requests to /api/v1/query_range . For example, the /ap1/v1/query Path Config uses the query and time URL query qarameters when creating the cache key, and is routed through the Object Proxy Cache; while the /api/v1/query_range Path Config uses the query , start , end and step parameters, and is routed through the Time Series Delta Proxy Cache. In the Trickster config file, you can add your own Path Configs to your time series origin, as well override individual settings for any of the pre-defined Path Configs, and those custom settings will be applied at startup. To know what configs you'd like to add or modify, take a look at the Trickster source code and examine the pre-definitions for the selected Origin Type. Each supported Origin Type's handlers and default Path Configs can be viewed under /internal/proxy/origins/<origin_type>/routes.go . These files are in a standard format that are quite human-readable, even for a non-coder, so don't be too intimidated. If you can understand Path Configs as TOML, you can understand them as Go code. Examples of customizing Path Configs for Origin Types with Pre-Definitions: [origins] [origins.default] provider = 'prometheus' [origins.default.paths] # route /api/v1/label* (including /labels/*) # through Proxy instead of ProxyCache as pre-defined [origins.default.paths.label] path = '/api/v1/label' methods = [ 'GET' ] match_type = 'prefix' handler = 'proxy' # route fictional new /api/v1/coffee to ProxyCache [origins.default.paths.series_range] path = '/api/v1/coffee' methods = [ 'GET' ] match_type = 'prefix' handler = 'proxycache' cache_key_params = [ 'beans' ] # block /api/v1/admin/ from being reachable via Trickster [origins.default.paths.admin] path = '/api/v1/admin/' methods = [ 'GET', 'POST', 'PUT', 'HEAD', 'DELETE', 'OPTIONS' ] match_type = 'prefix' handler = 'localresponse' response_code = 401 response_body = 'No soup for you!' no_metrics = true","title":"Modifying Behavior of Time Series Origin Types"},{"location":"per-query-instructions/","text":"Per-Query Time Series Instructions Beginning with Trickster v1.1, certain features like Fast Forward can be toggled a per-query basis, to assist with compatibility in your environment. This allows the drafters of a query to have some say over toggling these features on queries they find to have issues running through Trickster. This is done by adding directives via query comments. For example, in Prometheus, you can end any query with # any comment following a hashtag , so you can place the per-query instructions there. Supported Per-Query Instructions Fast Forward Disable Instruction trickster-fast-forward Supported for: Prometheus (other time series do not currently implement Fast Forward) Usage: go_goroutines{job=\"trickster\"} # trickster-fast-forward:off Notes: This can only be used to disable fast forward. A value of on will have no effect. Backfill Tolerance Instruction trickster-backfill-tolerance Supported for: All time series origins Usage: SELECT time, count(*) FROM table # trickster-backfill-tolerance:120 Notes: This overrides the backfill tolerance value for this query by the specified value (in seconds). Only integers are accepted.","title":"Per-Query Time Series Instructions"},{"location":"per-query-instructions/#per-query-time-series-instructions","text":"Beginning with Trickster v1.1, certain features like Fast Forward can be toggled a per-query basis, to assist with compatibility in your environment. This allows the drafters of a query to have some say over toggling these features on queries they find to have issues running through Trickster. This is done by adding directives via query comments. For example, in Prometheus, you can end any query with # any comment following a hashtag , so you can place the per-query instructions there.","title":"Per-Query Time Series Instructions"},{"location":"per-query-instructions/#supported-per-query-instructions","text":"","title":"Supported Per-Query Instructions"},{"location":"per-query-instructions/#fast-forward-disable","text":"Instruction trickster-fast-forward Supported for: Prometheus (other time series do not currently implement Fast Forward) Usage: go_goroutines{job=\"trickster\"} # trickster-fast-forward:off Notes: This can only be used to disable fast forward. A value of on will have no effect.","title":"Fast Forward Disable"},{"location":"per-query-instructions/#backfill-tolerance","text":"Instruction trickster-backfill-tolerance Supported for: All time series origins Usage: SELECT time, count(*) FROM table # trickster-backfill-tolerance:120 Notes: This overrides the backfill tolerance value for this query by the specified value (in seconds). Only integers are accepted.","title":"Backfill Tolerance"},{"location":"placement/","text":"Where to Place Trickster Depending upon the size of your existing or planned deployment, there are several placement configurations available. These designs are suggestions based on common usage, and you may find alternative or hybrid placement configurations that make the most sense for your situation, based on the activity of your Dashboard and TSDB instance(s). Single \"Everything\" Single \"Everything\" is the most common placement model. In this configuration, you have one optional dashboard endpoint, one Trickster endpoint and one HTTP or TSDB endpoint. Behind each endpoint, you may have a single instance or a cluster. Each component is only aware of the other component's endpoint exposure and not the underlying configuration. This configuration represents a one-for-one-for-one deployment of your Dashboard, Origin, and Trickster endpoints. Multiple Origins In a Multi-Origin placement, you have one dashboard endpoint, one Trickster endpoint, and multiple TSDB and/or HTTP endpoints. Trickster is aware of each upstream endpoint and treats each as a unique origin to which it proxies and caches data independently from the others. Trickster selects the origin based on Host Header or URL Path from the client request. This setup may benefit situations where you have one ore more a static file server origins serving HTML, CSS and JavaScript assets and/or one or more API endpoints, all supporting a common platform. For Time Series Dasbhoard acceleration, this is a good configuration to use when you have a single dashboard that displays data about multiple redundant clusters (each with its own TSDB), or when you have a single dashboard representing information about many different kinds of systems. For example, if you operate a \"Dashboard as a Service\" solution under which many teams use your Dashboard system by designing their own dashboard screens and bringing their own databases, a single Trickster endpoint can be used to accelerate dashboards for all of your customers. You will need to configure each Trickster-to-TSDB mapping separately in your dashboard application as a separately named TSDB data source. Refer to the multi-origin documentation for configuring multi-origin support in Trickster and Grafana. In this configuration, be aware that the default 'memory' cache may be underpowered depending on the number of customers, as well as the size and number of queries that need to be cached by each customer. Refer to the caches document to select and configure the caching layers as needed to meet your specific situation. Multi-Trickster In a Multi-Trickster configuration, you have one dashboard endpoint, multiple Trickster endpoints, and multiple TSDB or HTTP endpoints, with each Trickster Endpoint having a one-to-one mapping to a TSDB/HTTP Endpoint as a pair. This is a good design if Multi-Origin is not performant enough for the amount of activity associated with your solution (e.g., you need more Tricksters). If the Dashboard system owner is different from the TSDB system owner, either party could own and operate the Trickster instance.","title":"Where to Place Trickster"},{"location":"placement/#where-to-place-trickster","text":"Depending upon the size of your existing or planned deployment, there are several placement configurations available. These designs are suggestions based on common usage, and you may find alternative or hybrid placement configurations that make the most sense for your situation, based on the activity of your Dashboard and TSDB instance(s).","title":"Where to Place Trickster"},{"location":"placement/#single-everything","text":"Single \"Everything\" is the most common placement model. In this configuration, you have one optional dashboard endpoint, one Trickster endpoint and one HTTP or TSDB endpoint. Behind each endpoint, you may have a single instance or a cluster. Each component is only aware of the other component's endpoint exposure and not the underlying configuration. This configuration represents a one-for-one-for-one deployment of your Dashboard, Origin, and Trickster endpoints.","title":"Single \"Everything\""},{"location":"placement/#multiple-origins","text":"In a Multi-Origin placement, you have one dashboard endpoint, one Trickster endpoint, and multiple TSDB and/or HTTP endpoints. Trickster is aware of each upstream endpoint and treats each as a unique origin to which it proxies and caches data independently from the others. Trickster selects the origin based on Host Header or URL Path from the client request. This setup may benefit situations where you have one ore more a static file server origins serving HTML, CSS and JavaScript assets and/or one or more API endpoints, all supporting a common platform. For Time Series Dasbhoard acceleration, this is a good configuration to use when you have a single dashboard that displays data about multiple redundant clusters (each with its own TSDB), or when you have a single dashboard representing information about many different kinds of systems. For example, if you operate a \"Dashboard as a Service\" solution under which many teams use your Dashboard system by designing their own dashboard screens and bringing their own databases, a single Trickster endpoint can be used to accelerate dashboards for all of your customers. You will need to configure each Trickster-to-TSDB mapping separately in your dashboard application as a separately named TSDB data source. Refer to the multi-origin documentation for configuring multi-origin support in Trickster and Grafana. In this configuration, be aware that the default 'memory' cache may be underpowered depending on the number of customers, as well as the size and number of queries that need to be cached by each customer. Refer to the caches document to select and configure the caching layers as needed to meet your specific situation.","title":"Multiple Origins"},{"location":"placement/#multi-trickster","text":"In a Multi-Trickster configuration, you have one dashboard endpoint, multiple Trickster endpoints, and multiple TSDB or HTTP endpoints, with each Trickster Endpoint having a one-to-one mapping to a TSDB/HTTP Endpoint as a pair. This is a good design if Multi-Origin is not performant enough for the amount of activity associated with your solution (e.g., you need more Tricksters). If the Dashboard system owner is different from the TSDB system owner, either party could own and operate the Trickster instance.","title":"Multi-Trickster"},{"location":"promsim/","text":"PromSim Update We've created a new project called Mockster that incorporates all the features of PromSim, verbatim. We hope you'll check it out! The PromSim packages and libraries are removed from the main Trickster project, and we'll remove this notice with the release of Trickster v1.2.","title":"PromSim Update"},{"location":"promsim/#promsim-update","text":"We've created a new project called Mockster that incorporates all the features of PromSim, verbatim. We hope you'll check it out! The PromSim packages and libraries are removed from the main Trickster project, and we'll remove this notice with the release of Trickster v1.2.","title":"PromSim Update"},{"location":"range_request/","text":"Byte Range Request Support Trickster's HTTP Reverse Proxy Cache offers best-in-class acceleration and caching of Byte Range Requests. Much like its Time Series Delta Proxy Cache, Trickster's Reverse Proxy Cache will determine what ranges are cached, and only request from the origin any uncached ranges needed to service the client request, reconstituting the ranges within the cache object. This ensures minimal response time for all Range requests. In addition to supporting requests with a single Range ( Range: bytes=0-5 ) Trickster also supports Multipart Range Requests ( Range: bytes=0-5, 10-20 ). Fronting Origins That Do Not Support Multipart Range Requests In the event that an upstream origin supports serving a single Range, but does not support serving Multipart Range Requests, which is quite common, Trickster can transparently enable that support on behalf of the origin. To do so, Trickster offers a unique feature called Upstream Range Dearticulation, that will separate any ranges needed from the origin into individual, parallel HTTP requests, which are reconstituted by Trickster. This behavior can be enabled for any origin that only supports serving a single Range, by setting the origin configuration value dearticulate_upstream_ranges = true , as in this example: [origins] [origins.default] provider = 'reverseproxycache' origin_url = 'http://example.com/' dearticulate_upstream_ranges = true If you know that your clients will be making Range requests (even if they are not Multipart), check to ensure the configured origin supports Multipart Range requests. Use curl to request any static object from the origin, for which you know the size, and include a Multipart Range request; like curl -v -H 'Range: bytes=0-1, 3-4' 'http://example.com/object.js' . If the origin returns 200 OK and the entire object body, instead of 206 Partial Content and a multipart body, enable Upstream Range Dearticulation to ensure optimal performance. This is important because a partial hit could result in multiple ranges being needed from the origin - even for a single-Range client request, depending upon what ranges are already in cache. If Upstream Range Dearticulation is disabled in this case, full objects could be uncessaritly returned from the Origin to Trickster, instead of small delta ranges, irrespective of the object's overall size. This may or may not impact your use case. Rule of thumb: If the origin does not support Multipart requests, enable Upstream Range Dearticulation in Trickster to compensate. Conversely, if the origin does support Multipart requests, do not enable Upstream Range Dearticulation. Disabling Multpart Ranges to Clients One of the great benefits of using Upstream Range Dearticulation is that it transparently enables Multipart Range support for clients, when fronting any origin that already supports serving just a single Range. There may, however, be cases where you do not want to enable Multipart Range support for clients (since its paired Origin does not), but need Upstream Range Dearticulation to optimize Partial Hit fulfillments. For those cases, Trickster offers a setting to disable Multipart Range support for clients, while Upstream Range Dearticulation is enabled. Set multipart_ranges_disabled = true , as in the below example, and Trickster will strip Multipart Range Request headers, which will result in a 200 OK response with the full body. Client single Range requests are unaffected by this setting. This should only be set if you have a specific use case where clients should not be able to make multipart Range requests. [origins] [origins.default] provider = 'reverseproxycache' origin_url = 'http://example.com/' dearticulate_upstream_ranges = true multipart_ranges_disabled = true Partial Hit with Object Revalidation As explained above, whenever the client makes a Range request, and only part of the Range is in the Trickster cache, Trickster will fetch the uncached Ranges from the Origin, then reconstitute and cache all of the accumulated Ranges, while also replying to the client with its requested Ranges. In the event that a cache object returns 1) a partial hit, 2) that is no longer fresh, 3) but can be revalidated, based on a) the Origin's provided caching directives or b) overridden by the Trickster operator's explicit path-based Header configs ; Trickster will revalidate the client's requested-but-cached range from the origin with the appropriate revalidation headers. In a Partial Hit with Revalidation, the revalidation request is made as a separate, parallel request to the origin alongside the uncached range request(s). If the revalidation succeeds, the cached range is merged with the newly-fetched range as if it had never expired. If the revalidation fails, the Origin will return the range needed by the client that was previously cached, or potentially the entire object - either of which are used to complete the ranges needed by the client and update the cache and caching policy for the object. Range Miss with Object Revalidation Trickster recognizes when an object exists in cache, but has none of the client's requested Ranges. This is a state that lies between Cache Miss and Partial Hit, and is known as \"Range Miss.\" Range Misses can happen frequently on Range-requested objects. When a Range Miss occurs against an object that also requires revalidation, Trickster will not initiate a parallel revalidation request, since none of the client's requested Ranges are actually eligible for revalidation. Instead, Trickster will use the Response Headers returned by the Range Miss Request to perform a local revalidation of the cache object. If the object is revalidated, the new Ranges are merged with the cached Ranges before writing to cache based on the newly received Caching Policy. If the object is not revalidated, the cache object is created anew solely from the Range Miss Response. Multiple Parts Require Revalidation A situation can arise where there is a partial cache hit has multiple ranges that require revalidation before they can be used to satisfy the client. In these cases, Trickster will check if Upstream Range Dearticulation is enabled for the origin to determine how to resolve this condition. If Upstream Range Dearticulation is not enabled, Trickster trusts that the upstream origin will support Multipart Range Requests, and will include just the client's needed-and-cached-but-expired ranges in the revalidation request. If Upstream Range Dearticulation is enabled, Trickster will forward, without modification, the client's requested Ranges to the revalidation request to the origin. This behavior means Trickster currently does not support multiple parallel revalidations requests. Whenever the cache object requires revalidation, there will be only 1 revalidation request upstream, and 0 to N additional parallel upstream range requests as required to fulfill a partial hit. If-Range Not Yet Supported Trickster currently does not support revalidation based on If-Range request headers, for use with partial download resumptions by clients. If-Range headers are simply ignored by Trickster and passed through to the origin, which can result in unexpected behavior with the Trickster cache for that object. We plan to provide full support for If-Range as part of Trickster 1.1 or 1.2. Mockster Byte Range For verification of Trickster's compatibility with Byte Range Requests (as well as Time Series data), we created a golang library and accompanying standalone application dubbed Mockster. Mockster's Byte Range library simply prints out the Lorem ipsum ... sample text, pared down to the requested range or multipart ranges, with a few bells and whistles that allow you to customize its response for unit testing purposes. We make extensive use of Mockster in unit testing to verify the integrity of Trickster's output after performing operations like merging disparate range parts, extracting ranges from other ranges, or from a full body, compressing adjacent ranges into a single range in the cache, etc. It is fairly straightforward to run or import Mockster into your own applications. For examples of using it for Unit Testing, check out /internal/proxy/engines/objectproxycache_test.go .","title":"Byte Range Request Support"},{"location":"range_request/#byte-range-request-support","text":"Trickster's HTTP Reverse Proxy Cache offers best-in-class acceleration and caching of Byte Range Requests. Much like its Time Series Delta Proxy Cache, Trickster's Reverse Proxy Cache will determine what ranges are cached, and only request from the origin any uncached ranges needed to service the client request, reconstituting the ranges within the cache object. This ensures minimal response time for all Range requests. In addition to supporting requests with a single Range ( Range: bytes=0-5 ) Trickster also supports Multipart Range Requests ( Range: bytes=0-5, 10-20 ).","title":"Byte Range Request Support"},{"location":"range_request/#fronting-origins-that-do-not-support-multipart-range-requests","text":"In the event that an upstream origin supports serving a single Range, but does not support serving Multipart Range Requests, which is quite common, Trickster can transparently enable that support on behalf of the origin. To do so, Trickster offers a unique feature called Upstream Range Dearticulation, that will separate any ranges needed from the origin into individual, parallel HTTP requests, which are reconstituted by Trickster. This behavior can be enabled for any origin that only supports serving a single Range, by setting the origin configuration value dearticulate_upstream_ranges = true , as in this example: [origins] [origins.default] provider = 'reverseproxycache' origin_url = 'http://example.com/' dearticulate_upstream_ranges = true If you know that your clients will be making Range requests (even if they are not Multipart), check to ensure the configured origin supports Multipart Range requests. Use curl to request any static object from the origin, for which you know the size, and include a Multipart Range request; like curl -v -H 'Range: bytes=0-1, 3-4' 'http://example.com/object.js' . If the origin returns 200 OK and the entire object body, instead of 206 Partial Content and a multipart body, enable Upstream Range Dearticulation to ensure optimal performance. This is important because a partial hit could result in multiple ranges being needed from the origin - even for a single-Range client request, depending upon what ranges are already in cache. If Upstream Range Dearticulation is disabled in this case, full objects could be uncessaritly returned from the Origin to Trickster, instead of small delta ranges, irrespective of the object's overall size. This may or may not impact your use case. Rule of thumb: If the origin does not support Multipart requests, enable Upstream Range Dearticulation in Trickster to compensate. Conversely, if the origin does support Multipart requests, do not enable Upstream Range Dearticulation.","title":"Fronting Origins That Do Not Support Multipart Range Requests"},{"location":"range_request/#disabling-multpart-ranges-to-clients","text":"One of the great benefits of using Upstream Range Dearticulation is that it transparently enables Multipart Range support for clients, when fronting any origin that already supports serving just a single Range. There may, however, be cases where you do not want to enable Multipart Range support for clients (since its paired Origin does not), but need Upstream Range Dearticulation to optimize Partial Hit fulfillments. For those cases, Trickster offers a setting to disable Multipart Range support for clients, while Upstream Range Dearticulation is enabled. Set multipart_ranges_disabled = true , as in the below example, and Trickster will strip Multipart Range Request headers, which will result in a 200 OK response with the full body. Client single Range requests are unaffected by this setting. This should only be set if you have a specific use case where clients should not be able to make multipart Range requests. [origins] [origins.default] provider = 'reverseproxycache' origin_url = 'http://example.com/' dearticulate_upstream_ranges = true multipart_ranges_disabled = true","title":"Disabling Multpart Ranges to Clients"},{"location":"range_request/#partial-hit-with-object-revalidation","text":"As explained above, whenever the client makes a Range request, and only part of the Range is in the Trickster cache, Trickster will fetch the uncached Ranges from the Origin, then reconstitute and cache all of the accumulated Ranges, while also replying to the client with its requested Ranges. In the event that a cache object returns 1) a partial hit, 2) that is no longer fresh, 3) but can be revalidated, based on a) the Origin's provided caching directives or b) overridden by the Trickster operator's explicit path-based Header configs ; Trickster will revalidate the client's requested-but-cached range from the origin with the appropriate revalidation headers. In a Partial Hit with Revalidation, the revalidation request is made as a separate, parallel request to the origin alongside the uncached range request(s). If the revalidation succeeds, the cached range is merged with the newly-fetched range as if it had never expired. If the revalidation fails, the Origin will return the range needed by the client that was previously cached, or potentially the entire object - either of which are used to complete the ranges needed by the client and update the cache and caching policy for the object.","title":"Partial Hit with Object Revalidation"},{"location":"range_request/#range-miss-with-object-revalidation","text":"Trickster recognizes when an object exists in cache, but has none of the client's requested Ranges. This is a state that lies between Cache Miss and Partial Hit, and is known as \"Range Miss.\" Range Misses can happen frequently on Range-requested objects. When a Range Miss occurs against an object that also requires revalidation, Trickster will not initiate a parallel revalidation request, since none of the client's requested Ranges are actually eligible for revalidation. Instead, Trickster will use the Response Headers returned by the Range Miss Request to perform a local revalidation of the cache object. If the object is revalidated, the new Ranges are merged with the cached Ranges before writing to cache based on the newly received Caching Policy. If the object is not revalidated, the cache object is created anew solely from the Range Miss Response.","title":"Range Miss with Object Revalidation"},{"location":"range_request/#multiple-parts-require-revalidation","text":"A situation can arise where there is a partial cache hit has multiple ranges that require revalidation before they can be used to satisfy the client. In these cases, Trickster will check if Upstream Range Dearticulation is enabled for the origin to determine how to resolve this condition. If Upstream Range Dearticulation is not enabled, Trickster trusts that the upstream origin will support Multipart Range Requests, and will include just the client's needed-and-cached-but-expired ranges in the revalidation request. If Upstream Range Dearticulation is enabled, Trickster will forward, without modification, the client's requested Ranges to the revalidation request to the origin. This behavior means Trickster currently does not support multiple parallel revalidations requests. Whenever the cache object requires revalidation, there will be only 1 revalidation request upstream, and 0 to N additional parallel upstream range requests as required to fulfill a partial hit.","title":"Multiple Parts Require Revalidation"},{"location":"range_request/#if-range-not-yet-supported","text":"Trickster currently does not support revalidation based on If-Range request headers, for use with partial download resumptions by clients. If-Range headers are simply ignored by Trickster and passed through to the origin, which can result in unexpected behavior with the Trickster cache for that object. We plan to provide full support for If-Range as part of Trickster 1.1 or 1.2.","title":"If-Range Not Yet Supported"},{"location":"range_request/#mockster-byte-range","text":"For verification of Trickster's compatibility with Byte Range Requests (as well as Time Series data), we created a golang library and accompanying standalone application dubbed Mockster. Mockster's Byte Range library simply prints out the Lorem ipsum ... sample text, pared down to the requested range or multipart ranges, with a few bells and whistles that allow you to customize its response for unit testing purposes. We make extensive use of Mockster in unit testing to verify the integrity of Trickster's output after performing operations like merging disparate range parts, extracting ranges from other ranges, or from a full body, compressing adjacent ranges into a single range in the cache, etc. It is fairly straightforward to run or import Mockster into your own applications. For examples of using it for Unit Testing, check out /internal/proxy/engines/objectproxycache_test.go .","title":"Mockster Byte Range"},{"location":"request_rewriters/","text":"Request Rewriters A Request Rewriter is a named series of instructions that modifies any part of the incoming HTTP request. Request Rewriters are used in various parts of the Trickster configuration to make scoped changes. For example, a rewriter can modify the path, headers, parameters, etc. of a URL using mechanisms like search/replace, set and append. In a configuration, request rewriters are represented as map of instructions, which themselves are represented as a list of string lists, in the following format: [rewriters] [rewriters.example_rewriter] instructions = [ [ 'header', 'set', 'Cache-Control', 'max-age=60 ], # instruction 0 [ 'path', 'replace', '/cgi-bin/', '/' ], # instruction 1 ] In this case, any other configuration entity that supports mapping to a rewriter by name can do so with by referencing example_rewriter . Where Rewriters Can Be Used Rewriters are exposed as optional configurations for the following configuration constructs: In an origin config, provide a req_rewriter_name to rewrite the Request using the named Request Rewriter, before it is handled by the Path route. In a path config, provide a req_rewriter_name to rewrite the Request using the named Request Rewriter, before it is handled by the Path route. In a rule config, provide ingress_req_rewriter_name , egress_req_rewriter_name and/or nomatch_req_rewriter_name configurations to rewrite the Request using the named Request Rewriter. The meaning of Ingress and Egress, in this case, are scoped to a Request's traversal through the Rule in which these configuration values exist, and is unrelated to the wire traversal of the request. For ingress and egress, the rewriter is executed before or after, respectively, it is handled by the Rule (including any modifications made by a matching rule case). The No-Match Request Rewriter is only executed when the request does not match to any defined case. In a Rule's case configurations, provide req_rewriter_name . If there is a Rule Case match when executing the Rule against the incoming Request, the configured rewriter will execute on the Request before returning control back to the Rule to execute any configured egress request rewriter and hand the Request off to the next route. Instruction Construction Guide header header rewriters modify a header with a specific name and support the following operations. header set header set will set a specific header to a specific value. ['header', 'set', 'Header-Name', 'header value'] header replace header replace performs a search/replace function on the Header value of the provided Name ['header', 'replace', 'Header-Name', 'search value', 'replacement value'] header delete header delete removes, if present, the Header of the provided Name ['header', 'delete', 'Header-Name'] header append header append appends an additional value to Header in the format of value1[, value2=subvalue, ...] ['header', 'append', 'Header-Name', 'additional header value'] path path rewriters modify the full or partial path and support the following operations. path set ['path', 'set', '/new/path'] sets the entire request path to /new/path ['path', 'set', 'awesome', 0 ] sets the first part of the path (zero-indexed, split on / ) to 'awesome'. For example, /new/path => /awesome/path path replace ['path', 'replace', 'search', 'replacement'] search replaces against the entire path scalar ['path', 'replace', 'search', 'replacement', 1] search replaces against the second part of the path; For example /my/example-search/path => /my/example-replacement/path param param rewriters modify the URL Query Parameter of the specified name, and support the following operations param set param set sets the URL Query Parameter of the provided name to the provided value ['param', 'set', 'paramName', 'new param value'] param replace param replace performs a search/replace function on the URL Query Parameter value of the provided name ['param', 'replace', 'paramName', 'search value', 'replacement value'] param delete param delete removes, if present, the URL Query Parameter of the provided name ['param', 'delete', 'paramName'] param append param append appends the provided name and value to the URL Query Parameters regardless of whether a parameter name already exists with the same or different value. ['param', 'append', 'paramName', 'additional param value'] params params rewriters update the entire URL parameter collection as a URL-encoded scalar string. params set params set will replace the Request's entire URL Query Parameter encoded string with the provided value. The provided value is assumed to already be URL-encoded. ['params', 'set', 'param1=value1&param2=value2'] To clear the URL parameters, use ['params', 'set', ''] params replace params replace performs a search/replace operation on the url-encoded query string. The search and replacement values are assumed to already be URL-encoded. ['params', 'replace', 'search value', 'replacement value'] method method rewriters update the HTTP request's method method set method set sets the Request's HTTP Method to the provided value. This value is not currently validated against known HTTP Method. The instruction should be configured to include a known and properly-formatted (all caps) HTTP Method. ['method', 'set', 'GET'] host host rewriters update the HTTP Request's host - defined as the hostname:port, as expressed in the Request's Host header. host set host set sets the Request's Host header to the provided value. ['host', 'set', 'my.new.hostname:9999'] ['host', 'set', 'my.new.hostname'] Trickster will assume a standard source port 80/443 depending upon the URL scheme host replace host replace performs a search/replace operation on the Request's Host Header. ['host', 'replace', ':8480', ''] ['host', 'replace', ':443', ':8443'] ['host', 'replace', 'example.com', 'tricksterproxy.io'] hostname hostname rewriters update the HTTP Request's hostname, without respect to the port. hostname set hostname set sets the Request's hostname, without changing the port. ['hostname', 'set', 'my.new.hostname'] hostname replace hostname replace performs a search/replace on the Request's hostname, without respect to the port. ['hostname', 'replace', 'example.com', 'tricksterproxy.io'] port port rewriters update the HTTP Request's port, without respect to the hostname. port set port set sets the Request's port. ['port', 'set', '8480'] port replace port replace performs a search/replace on the port, as if it was a string. The search and replacement values must be integers and are not validated. ['port', 'replace', '8480', ''] port delete port delete removes the port from the Request. This will cause the port to be assumed based on the URL scheme. ['port', 'delete'] scheme scheme rewriters update the HTTP Request's scheme ( http or https ). scheme set scheme set sets the scheme of the HTTP Request URL. This must be http or https in lowercase, and is not validated. ['scheme', 'set', 'https']","title":"Request Rewriters"},{"location":"request_rewriters/#request-rewriters","text":"A Request Rewriter is a named series of instructions that modifies any part of the incoming HTTP request. Request Rewriters are used in various parts of the Trickster configuration to make scoped changes. For example, a rewriter can modify the path, headers, parameters, etc. of a URL using mechanisms like search/replace, set and append. In a configuration, request rewriters are represented as map of instructions, which themselves are represented as a list of string lists, in the following format: [rewriters] [rewriters.example_rewriter] instructions = [ [ 'header', 'set', 'Cache-Control', 'max-age=60 ], # instruction 0 [ 'path', 'replace', '/cgi-bin/', '/' ], # instruction 1 ] In this case, any other configuration entity that supports mapping to a rewriter by name can do so with by referencing example_rewriter .","title":"Request Rewriters"},{"location":"request_rewriters/#where-rewriters-can-be-used","text":"Rewriters are exposed as optional configurations for the following configuration constructs: In an origin config, provide a req_rewriter_name to rewrite the Request using the named Request Rewriter, before it is handled by the Path route. In a path config, provide a req_rewriter_name to rewrite the Request using the named Request Rewriter, before it is handled by the Path route. In a rule config, provide ingress_req_rewriter_name , egress_req_rewriter_name and/or nomatch_req_rewriter_name configurations to rewrite the Request using the named Request Rewriter. The meaning of Ingress and Egress, in this case, are scoped to a Request's traversal through the Rule in which these configuration values exist, and is unrelated to the wire traversal of the request. For ingress and egress, the rewriter is executed before or after, respectively, it is handled by the Rule (including any modifications made by a matching rule case). The No-Match Request Rewriter is only executed when the request does not match to any defined case. In a Rule's case configurations, provide req_rewriter_name . If there is a Rule Case match when executing the Rule against the incoming Request, the configured rewriter will execute on the Request before returning control back to the Rule to execute any configured egress request rewriter and hand the Request off to the next route.","title":"Where Rewriters Can Be Used"},{"location":"request_rewriters/#instruction-construction-guide","text":"","title":"Instruction Construction Guide"},{"location":"request_rewriters/#header","text":"header rewriters modify a header with a specific name and support the following operations.","title":"header"},{"location":"request_rewriters/#header-set","text":"header set will set a specific header to a specific value. ['header', 'set', 'Header-Name', 'header value']","title":"header set"},{"location":"request_rewriters/#header-replace","text":"header replace performs a search/replace function on the Header value of the provided Name ['header', 'replace', 'Header-Name', 'search value', 'replacement value']","title":"header replace"},{"location":"request_rewriters/#header-delete","text":"header delete removes, if present, the Header of the provided Name ['header', 'delete', 'Header-Name']","title":"header delete"},{"location":"request_rewriters/#header-append","text":"header append appends an additional value to Header in the format of value1[, value2=subvalue, ...] ['header', 'append', 'Header-Name', 'additional header value']","title":"header append"},{"location":"request_rewriters/#path","text":"path rewriters modify the full or partial path and support the following operations.","title":"path"},{"location":"request_rewriters/#path-set","text":"['path', 'set', '/new/path'] sets the entire request path to /new/path ['path', 'set', 'awesome', 0 ] sets the first part of the path (zero-indexed, split on / ) to 'awesome'. For example, /new/path => /awesome/path","title":"path set"},{"location":"request_rewriters/#path-replace","text":"['path', 'replace', 'search', 'replacement'] search replaces against the entire path scalar ['path', 'replace', 'search', 'replacement', 1] search replaces against the second part of the path; For example /my/example-search/path => /my/example-replacement/path","title":"path replace"},{"location":"request_rewriters/#param","text":"param rewriters modify the URL Query Parameter of the specified name, and support the following operations","title":"param"},{"location":"request_rewriters/#param-set","text":"param set sets the URL Query Parameter of the provided name to the provided value ['param', 'set', 'paramName', 'new param value']","title":"param set"},{"location":"request_rewriters/#param-replace","text":"param replace performs a search/replace function on the URL Query Parameter value of the provided name ['param', 'replace', 'paramName', 'search value', 'replacement value']","title":"param replace"},{"location":"request_rewriters/#param-delete","text":"param delete removes, if present, the URL Query Parameter of the provided name ['param', 'delete', 'paramName']","title":"param delete"},{"location":"request_rewriters/#param-append","text":"param append appends the provided name and value to the URL Query Parameters regardless of whether a parameter name already exists with the same or different value. ['param', 'append', 'paramName', 'additional param value']","title":"param append"},{"location":"request_rewriters/#params","text":"params rewriters update the entire URL parameter collection as a URL-encoded scalar string.","title":"params"},{"location":"request_rewriters/#params-set","text":"params set will replace the Request's entire URL Query Parameter encoded string with the provided value. The provided value is assumed to already be URL-encoded. ['params', 'set', 'param1=value1&param2=value2'] To clear the URL parameters, use ['params', 'set', '']","title":"params set"},{"location":"request_rewriters/#params-replace","text":"params replace performs a search/replace operation on the url-encoded query string. The search and replacement values are assumed to already be URL-encoded. ['params', 'replace', 'search value', 'replacement value']","title":"params replace"},{"location":"request_rewriters/#method","text":"method rewriters update the HTTP request's method","title":"method"},{"location":"request_rewriters/#method-set","text":"method set sets the Request's HTTP Method to the provided value. This value is not currently validated against known HTTP Method. The instruction should be configured to include a known and properly-formatted (all caps) HTTP Method. ['method', 'set', 'GET']","title":"method set"},{"location":"request_rewriters/#host","text":"host rewriters update the HTTP Request's host - defined as the hostname:port, as expressed in the Request's Host header.","title":"host"},{"location":"request_rewriters/#host-set","text":"host set sets the Request's Host header to the provided value. ['host', 'set', 'my.new.hostname:9999'] ['host', 'set', 'my.new.hostname'] Trickster will assume a standard source port 80/443 depending upon the URL scheme","title":"host set"},{"location":"request_rewriters/#host-replace","text":"host replace performs a search/replace operation on the Request's Host Header. ['host', 'replace', ':8480', ''] ['host', 'replace', ':443', ':8443'] ['host', 'replace', 'example.com', 'tricksterproxy.io']","title":"host replace"},{"location":"request_rewriters/#hostname","text":"hostname rewriters update the HTTP Request's hostname, without respect to the port.","title":"hostname"},{"location":"request_rewriters/#hostname-set","text":"hostname set sets the Request's hostname, without changing the port. ['hostname', 'set', 'my.new.hostname']","title":"hostname set"},{"location":"request_rewriters/#hostname-replace","text":"hostname replace performs a search/replace on the Request's hostname, without respect to the port. ['hostname', 'replace', 'example.com', 'tricksterproxy.io']","title":"hostname replace"},{"location":"request_rewriters/#port","text":"port rewriters update the HTTP Request's port, without respect to the hostname.","title":"port"},{"location":"request_rewriters/#port-set","text":"port set sets the Request's port. ['port', 'set', '8480']","title":"port set"},{"location":"request_rewriters/#port-replace","text":"port replace performs a search/replace on the port, as if it was a string. The search and replacement values must be integers and are not validated. ['port', 'replace', '8480', '']","title":"port replace"},{"location":"request_rewriters/#port-delete","text":"port delete removes the port from the Request. This will cause the port to be assumed based on the URL scheme. ['port', 'delete']","title":"port delete"},{"location":"request_rewriters/#scheme","text":"scheme rewriters update the HTTP Request's scheme ( http or https ).","title":"scheme"},{"location":"request_rewriters/#scheme-set","text":"scheme set sets the scheme of the HTTP Request URL. This must be http or https in lowercase, and is not validated. ['scheme', 'set', 'https']","title":"scheme set"},{"location":"retention/","text":"Trickster Caching Retention Policies Basic HTTP Origins Trickster will respect HTTP 1.0, 1.1 and 2.0 caching directives from both the downstream client and the upstream origin when determining objectly cacheability and TTL. You can override the TTL by setting a custom Cache-Control header on a per- Path Config basis. Cache Object Evictions If you use a Trickster-managed cache (Memory, Filesystem, bbolt), then a maximum cache size is maintained by Trickster. You can configure the maximum size in number of bytes, number of objects, or both. See the example configuration for more information. Once the cache has reached its configured maximum size of objects or bytes, Trickster will undergo an eviction routine that removes cache objects until the size has fallen below the configured maximums. Trickster-managed caches maintain a last access time for each cache object, and utilizes a Least Recently Used (LRU) methodology when selecting objects for eviction. Caches whose object lifetimes are not managed internally by Trickster (Redis, BadgerDB) will use their own policies and methodologies for evicting cache records. Time Series Origins For non-time series responses from a TSDB, Trickster will adhere to HTTP caching rules as directed by the downstream client and upstream origin. For time series data responses, Trickster will cache as follows: TTL Settings TTL settings for each Origin configured in Trickster can be customized independently of each other, and separate TTL configurations are available for timeseries objects, and fast forward data. See cmd/trickster/conf/example.conf for more info on configuring default TTLs. Time Series Data Retention Separately from the TTL of a time series cache object, Trickster allows you to control the size of each timeseries object, represented as a count of maximum timestamps in the cache object, on a per origin basis. This configuration is known as the timeseries_retention_factor (TRF), and has a default of 1024. Most dashboards for most users request and display approximately 300-to-400 timestamps, so the default TRF allows users to still recall recently-displayed data from the Trickster cache for a period of time after the data has aged off of real-time views. If you have users with a high-resolution dashboard configuration (e.g., a 24-hour view with a 1-minute step, amounting to 1440 data points per graph), then you may benefit from increasing the timeseries_retention_factor accordingly. If you use a managed cache (see caches ) and increase the timeseries_retention_factor , the overall size of your cache will not change; the result will be fewer objects in cache, with the timeseries objects having a larger share of the overall cache size with more aged data. Time Series Data Evictions Once the TRF is reached for a time series cache object, Trickster will undergo a timestamp eviction process for the record in question. Unlike the Cache Object Eviction, which removes an object from cache completely, TRF evictions examine the data set contained in a cache object and remove timestamped data in order to reduce the object size down to the TRF. Time Series Data Evictions apply to all cached time seres data sets, regardless of whether or not the cache object lifecycle is managed by Trickster. Trickster provides two eviction methodologies ( timeseries_eviction_method ) for time series data eviction: oldest (default) and lru , and is configurable per-origin. When timeseries_eviction_method is set to oldest , Trickster maintains time series data by calculating the \"oldest cacheable timestamp\" value upon each request, using time.Now().Add(step * timeseries_retention_factor * -1) . Any queries for data older than the oldest cacheable timestamp are intelligently offloaded to the proxy since they will never be cached, and no data that is older than the oldest cacheable timestamp will be stored in the query's cache record. When timeseries_eviction_method is set to lru , Trickster will not calculate an oldest cacheable timestamp, but rather maintain a last-accessed time for each timestamp in the cache object, and evict the Least-Recently-Used items in order to maintian the cache size. The advantage of the oldest methodology better cache performance, at the cost of not caching very old data. Thus, Trickster will be more performant computationally while providing a slightly lower cache hit rate. The lru methodology, since it requires accessing the cache on every request and maintaining access times for every timestamp, is computationally more expensive, but can achieve a higher cache hit rate since it permits caching data of any age, so long as it is accessed frequently enough to avoid eviction. Most users will find the oldest methodology to meet their needs, so it is recommended to use lru only if you have a specific use case (e.g., dashboards with data from a diverse set of time ranges, where caching only relatively young data does not suffice).","title":"Trickster Caching Retention Policies"},{"location":"retention/#trickster-caching-retention-policies","text":"","title":"Trickster Caching Retention Policies"},{"location":"retention/#basic-http-origins","text":"Trickster will respect HTTP 1.0, 1.1 and 2.0 caching directives from both the downstream client and the upstream origin when determining objectly cacheability and TTL. You can override the TTL by setting a custom Cache-Control header on a per- Path Config basis.","title":"Basic HTTP Origins"},{"location":"retention/#cache-object-evictions","text":"If you use a Trickster-managed cache (Memory, Filesystem, bbolt), then a maximum cache size is maintained by Trickster. You can configure the maximum size in number of bytes, number of objects, or both. See the example configuration for more information. Once the cache has reached its configured maximum size of objects or bytes, Trickster will undergo an eviction routine that removes cache objects until the size has fallen below the configured maximums. Trickster-managed caches maintain a last access time for each cache object, and utilizes a Least Recently Used (LRU) methodology when selecting objects for eviction. Caches whose object lifetimes are not managed internally by Trickster (Redis, BadgerDB) will use their own policies and methodologies for evicting cache records.","title":"Cache Object Evictions"},{"location":"retention/#time-series-origins","text":"For non-time series responses from a TSDB, Trickster will adhere to HTTP caching rules as directed by the downstream client and upstream origin. For time series data responses, Trickster will cache as follows:","title":"Time Series Origins"},{"location":"retention/#ttl-settings","text":"TTL settings for each Origin configured in Trickster can be customized independently of each other, and separate TTL configurations are available for timeseries objects, and fast forward data. See cmd/trickster/conf/example.conf for more info on configuring default TTLs.","title":"TTL Settings"},{"location":"retention/#time-series-data-retention","text":"Separately from the TTL of a time series cache object, Trickster allows you to control the size of each timeseries object, represented as a count of maximum timestamps in the cache object, on a per origin basis. This configuration is known as the timeseries_retention_factor (TRF), and has a default of 1024. Most dashboards for most users request and display approximately 300-to-400 timestamps, so the default TRF allows users to still recall recently-displayed data from the Trickster cache for a period of time after the data has aged off of real-time views. If you have users with a high-resolution dashboard configuration (e.g., a 24-hour view with a 1-minute step, amounting to 1440 data points per graph), then you may benefit from increasing the timeseries_retention_factor accordingly. If you use a managed cache (see caches ) and increase the timeseries_retention_factor , the overall size of your cache will not change; the result will be fewer objects in cache, with the timeseries objects having a larger share of the overall cache size with more aged data.","title":"Time Series Data Retention"},{"location":"retention/#time-series-data-evictions","text":"Once the TRF is reached for a time series cache object, Trickster will undergo a timestamp eviction process for the record in question. Unlike the Cache Object Eviction, which removes an object from cache completely, TRF evictions examine the data set contained in a cache object and remove timestamped data in order to reduce the object size down to the TRF. Time Series Data Evictions apply to all cached time seres data sets, regardless of whether or not the cache object lifecycle is managed by Trickster. Trickster provides two eviction methodologies ( timeseries_eviction_method ) for time series data eviction: oldest (default) and lru , and is configurable per-origin. When timeseries_eviction_method is set to oldest , Trickster maintains time series data by calculating the \"oldest cacheable timestamp\" value upon each request, using time.Now().Add(step * timeseries_retention_factor * -1) . Any queries for data older than the oldest cacheable timestamp are intelligently offloaded to the proxy since they will never be cached, and no data that is older than the oldest cacheable timestamp will be stored in the query's cache record. When timeseries_eviction_method is set to lru , Trickster will not calculate an oldest cacheable timestamp, but rather maintain a last-accessed time for each timestamp in the cache object, and evict the Least-Recently-Used items in order to maintian the cache size. The advantage of the oldest methodology better cache performance, at the cost of not caching very old data. Thus, Trickster will be more performant computationally while providing a slightly lower cache hit rate. The lru methodology, since it requires accessing the cache on every request and maintaining access times for every timestamp, is computationally more expensive, but can achieve a higher cache hit rate since it permits caching data of any age, so long as it is accessed frequently enough to avoid eviction. Most users will find the oldest methodology to meet their needs, so it is recommended to use lru only if you have a specific use case (e.g., dashboards with data from a diverse set of time ranges, where caching only relatively young data does not suffice).","title":"Time Series Data Evictions"},{"location":"roadmap/","text":"Trickster Roadmap The roadmap for Trickster in 2020 focuses on delivering incremental enhancements to the core Trickster application, as well as new supporting applications and cloud native integrations. Timeline Q1 2020 [x] Trickster 1.0 GA Release [x] Submit Helm charts to Helm Hub [x] Trickster v1.1 Release [x] Relocate project to tricksterproxy organization [x] Release Binaries for Windows [x] Change default frontend listen port to 8480 [x] Frontend HTTP 2.0 Support [x] Rules-based Request Routing and Rewriting [x] Use RWMutex for cache synchronization [x] Reload configuration without process restart [x] Add implementation-specific Tracing options in config [x] Additional performance improvements [x] Relocate and merge PromSim and RangeSim into a separate repo called mockster [x] Relocate Helm charts to a separate repo [x] Automate Helm chart releases via GitHub Workflows Q3 2020 [ ] Kubernetes Ingress Controller [ ] Submit Trickster for CNCF Sandbox Consideration [ ] Register Official Docker Hub Repositories [ ] Trickster v2.0 Beta Release Q4 2020 [ ] Trickster v2.0 GA Release [ ] Common Time Series Format used internally for all TSDBs [ ] Importable Golang Handler Package [ ] Origin Pools w/ health checking for high availability and timeseries merge [ ] L7 Load balancing: round robin, hash, latency, lru, fewest # conns [ ] HA Request Spray: serve first response, or HA merge of time series responses [ ] YAML config support [ ] Support for InfluxDB 2.0 and Flux syntax [ ] Extended support for ClickHouse [ ] Purge object from cache by path or key [ ] Short-term caching of non-timeseries read-only queries (e.g., SELECT statements) [ ] Benchster - RFC Compliance and Benchmarking Suite for Proxies How to Help You can help by contributing to Trickster, or trying it out in your environment. By giving Trickster a spin, you can help us identify and fix defects more quickly. Be sure to file issues if you find something wrong. If you can reliably reproduce the issue, provide detailed steps so that developers can more easily root-cause the issue. If you want to contribute to Trickster, we'd love the help. Please take any issue that is not already assigned as per the contributing guidelines, or check with the maintainers to find out how best to get involved. Thank You We are so excited to share the Trickster with the community. This is only possible through our great community of contributors, users and supporters. Thank you for all you in making this project a success!","title":"Trickster Roadmap"},{"location":"roadmap/#trickster-roadmap","text":"The roadmap for Trickster in 2020 focuses on delivering incremental enhancements to the core Trickster application, as well as new supporting applications and cloud native integrations.","title":"Trickster Roadmap"},{"location":"roadmap/#timeline","text":"","title":"Timeline"},{"location":"roadmap/#q1-2020","text":"[x] Trickster 1.0 GA Release [x] Submit Helm charts to Helm Hub [x] Trickster v1.1 Release [x] Relocate project to tricksterproxy organization [x] Release Binaries for Windows [x] Change default frontend listen port to 8480 [x] Frontend HTTP 2.0 Support [x] Rules-based Request Routing and Rewriting [x] Use RWMutex for cache synchronization [x] Reload configuration without process restart [x] Add implementation-specific Tracing options in config [x] Additional performance improvements [x] Relocate and merge PromSim and RangeSim into a separate repo called mockster [x] Relocate Helm charts to a separate repo [x] Automate Helm chart releases via GitHub Workflows","title":"Q1 2020"},{"location":"roadmap/#q3-2020","text":"[ ] Kubernetes Ingress Controller [ ] Submit Trickster for CNCF Sandbox Consideration [ ] Register Official Docker Hub Repositories [ ] Trickster v2.0 Beta Release","title":"Q3 2020"},{"location":"roadmap/#q4-2020","text":"[ ] Trickster v2.0 GA Release [ ] Common Time Series Format used internally for all TSDBs [ ] Importable Golang Handler Package [ ] Origin Pools w/ health checking for high availability and timeseries merge [ ] L7 Load balancing: round robin, hash, latency, lru, fewest # conns [ ] HA Request Spray: serve first response, or HA merge of time series responses [ ] YAML config support [ ] Support for InfluxDB 2.0 and Flux syntax [ ] Extended support for ClickHouse [ ] Purge object from cache by path or key [ ] Short-term caching of non-timeseries read-only queries (e.g., SELECT statements) [ ] Benchster - RFC Compliance and Benchmarking Suite for Proxies","title":"Q4 2020"},{"location":"roadmap/#how-to-help","text":"You can help by contributing to Trickster, or trying it out in your environment. By giving Trickster a spin, you can help us identify and fix defects more quickly. Be sure to file issues if you find something wrong. If you can reliably reproduce the issue, provide detailed steps so that developers can more easily root-cause the issue. If you want to contribute to Trickster, we'd love the help. Please take any issue that is not already assigned as per the contributing guidelines, or check with the maintainers to find out how best to get involved.","title":"How to Help"},{"location":"roadmap/#thank-you","text":"We are so excited to share the Trickster with the community. This is only possible through our great community of contributors, users and supporters. Thank you for all you in making this project a success!","title":"Thank You"},{"location":"rule/","text":"Rule Origin The Rule Origin is not really a true Origin; it only routes inbound requests to other configured Origins, based on how they match against the Rule's cases. A Rule is a single inspection operation performed against a single component of an inbound request, which determines the Next Origin to send the request to. The Next Origin can also be a rule Origin, so as to route requests through multiple Rules before arriving at a true Origin destination. A rule can optionally rewrite multiple portions of the request before, during and after rule matching, by using rewriters , which allows for powerful and limitless combinations of request rewriting and routing. Rule Parts A rule has several required parts, as follows: Required Rule Parts input_source - The part of the Request the Rule inspects input_type - The source data type operation - The operation taken on the input source next_route - The Origin Name indicating the default next route for the Rule if no matching cases. Not required if redirect_url is provided. redirect_url - The fully-qualified URL to issue as a 302 redirect to the client in the default case. Not required if next_route is provided. Optional Rule Parts input_key - case-sensitive lookup key; required when the source is header or URL param input_encoding - the encoding of the input, which is decoded prior to performing the operation input_index - when > -1, the source is split into parts and the input is extracted from parts[input_index] input-delimiter - when input_index > -1, this delimiter is used to split the source into parts, and defaults to a standard space (' ') ingress_req_rewriter name - provides the name of a Request Rewriter to operate on the Request before rule execution. egress_req_rewriter name - provides the name of a Request Rewriter to operate on the Request after rule execution. nomatch_req_rewriter name - provides the name of a Request Rewriter to operate on the Request after rule execution if the request did not match any cases. max_rule_executions - limits the number of rules a Request is passed through, and aborts with a 400 status code when exceeded. Default is 16. input_source permitted values source name example extracted value url https://example.com:8480/path1/path2?param1=value url_no_params https://example.com:8480/path1/path2 scheme https host example.com:8480 hostname example.com port 8480 (inferred from scheme when no port is provided) path /path1/path2 params ?param1=value param (must be used with input_key as described below) header (must be used with input_key as described below) input_type permitted values and operations type name permitted operations string (default) prefix, suffix, contains, eq, md5, sha1, modulo num eq, le, ge, gt, lt, modulo bool eq Rule Cases Rule cases define the possible values are able to alter the Request and change the next route. Case Parts Required Case Parts matches - A string list of values applicable to this case. next_route - The Origin Name indicating the next route for the Rule when a request matches this Case. Not required if redirect_url is provided. redirect_url - The fully-qualified URL to issue as a 302 redirect to the client when the Request matches this Case. Not required if next_route is provided. Optional Case Parts req_rewriter name - provides the name of a Request Rewriter to operate on the Request when this case is matched. Example Rule - Route Request by Basic Auth Username [rules] [rules.example-user-router] # default route is reader cluster next_route = 'example-reader-cluster' input_source = 'header' input_key = 'Authorization' input_type = 'string' input_encoding = 'base64' # Authorization: Basic <base64string> input_index = 1 # Field 1 is the <base64string> input_delimiter = ' ' # Authorization Header field is space-delimited operation = 'prefix' # Basic Auth credentials are formatted as user:pass, # so we can check if it is prefixed with $user: [rules.example-user-router.cases] [rules.example-user-router.cases.writers] matches = ['johndoe:', 'janedoe:'] # route johndoe and janedoe to writer cluster next_route = 'example-writer-cluster' [origins] [origins.example] provider = 'rule' rule_name = 'example-user-router' [origins.example-reader-cluster] provider = 'rpc' origin_url = 'http://reader-cluster.example.com' [origins.example-writer-cluster] provider = 'rpc' origin_url = 'http://writer-cluster.example.com' path_routing_disabled = true # restrict routing to this origin via rule only # users cannot directly access via /example-writer-cluster/ Curling http://trickster-host/example/path would route to the reader or writer cluster based on a provided Authorization header.","title":"Rule Origin"},{"location":"rule/#rule-origin","text":"The Rule Origin is not really a true Origin; it only routes inbound requests to other configured Origins, based on how they match against the Rule's cases. A Rule is a single inspection operation performed against a single component of an inbound request, which determines the Next Origin to send the request to. The Next Origin can also be a rule Origin, so as to route requests through multiple Rules before arriving at a true Origin destination. A rule can optionally rewrite multiple portions of the request before, during and after rule matching, by using rewriters , which allows for powerful and limitless combinations of request rewriting and routing.","title":"Rule Origin"},{"location":"rule/#rule-parts","text":"A rule has several required parts, as follows: Required Rule Parts input_source - The part of the Request the Rule inspects input_type - The source data type operation - The operation taken on the input source next_route - The Origin Name indicating the default next route for the Rule if no matching cases. Not required if redirect_url is provided. redirect_url - The fully-qualified URL to issue as a 302 redirect to the client in the default case. Not required if next_route is provided. Optional Rule Parts input_key - case-sensitive lookup key; required when the source is header or URL param input_encoding - the encoding of the input, which is decoded prior to performing the operation input_index - when > -1, the source is split into parts and the input is extracted from parts[input_index] input-delimiter - when input_index > -1, this delimiter is used to split the source into parts, and defaults to a standard space (' ') ingress_req_rewriter name - provides the name of a Request Rewriter to operate on the Request before rule execution. egress_req_rewriter name - provides the name of a Request Rewriter to operate on the Request after rule execution. nomatch_req_rewriter name - provides the name of a Request Rewriter to operate on the Request after rule execution if the request did not match any cases. max_rule_executions - limits the number of rules a Request is passed through, and aborts with a 400 status code when exceeded. Default is 16.","title":"Rule Parts"},{"location":"rule/#input_source-permitted-values","text":"source name example extracted value url https://example.com:8480/path1/path2?param1=value url_no_params https://example.com:8480/path1/path2 scheme https host example.com:8480 hostname example.com port 8480 (inferred from scheme when no port is provided) path /path1/path2 params ?param1=value param (must be used with input_key as described below) header (must be used with input_key as described below)","title":"input_source permitted values"},{"location":"rule/#input_type-permitted-values-and-operations","text":"type name permitted operations string (default) prefix, suffix, contains, eq, md5, sha1, modulo num eq, le, ge, gt, lt, modulo bool eq","title":"input_type permitted values and operations"},{"location":"rule/#rule-cases","text":"Rule cases define the possible values are able to alter the Request and change the next route.","title":"Rule Cases"},{"location":"rule/#case-parts","text":"Required Case Parts matches - A string list of values applicable to this case. next_route - The Origin Name indicating the next route for the Rule when a request matches this Case. Not required if redirect_url is provided. redirect_url - The fully-qualified URL to issue as a 302 redirect to the client when the Request matches this Case. Not required if next_route is provided. Optional Case Parts req_rewriter name - provides the name of a Request Rewriter to operate on the Request when this case is matched.","title":"Case Parts"},{"location":"rule/#example-rule-route-request-by-basic-auth-username","text":"[rules] [rules.example-user-router] # default route is reader cluster next_route = 'example-reader-cluster' input_source = 'header' input_key = 'Authorization' input_type = 'string' input_encoding = 'base64' # Authorization: Basic <base64string> input_index = 1 # Field 1 is the <base64string> input_delimiter = ' ' # Authorization Header field is space-delimited operation = 'prefix' # Basic Auth credentials are formatted as user:pass, # so we can check if it is prefixed with $user: [rules.example-user-router.cases] [rules.example-user-router.cases.writers] matches = ['johndoe:', 'janedoe:'] # route johndoe and janedoe to writer cluster next_route = 'example-writer-cluster' [origins] [origins.example] provider = 'rule' rule_name = 'example-user-router' [origins.example-reader-cluster] provider = 'rpc' origin_url = 'http://reader-cluster.example.com' [origins.example-writer-cluster] provider = 'rpc' origin_url = 'http://writer-cluster.example.com' path_routing_disabled = true # restrict routing to this origin via rule only # users cannot directly access via /example-writer-cluster/ Curling http://trickster-host/example/path would route to the reader or writer cluster based on a provided Authorization header.","title":"Example Rule - Route Request by Basic Auth Username"},{"location":"supported-origin-types/","text":"Supported Origin Types Trickster currently supports the following Origin Types: Generic HTTP Reverse Proxy Cache Trickster operates as a fully-featured and highly-customizable reverse proxy cache, designed to accellerate and scale upstream endpoints like API services and other simple http services. Specify 'reverseproxycache' or just 'rpc' as the Origin Type when configuring Trickster. Time Series Databases Prometheus Trickster fully supports the Prometheus HTTP API (v1) . Specify 'prometheus' as the Origin Type when configuring Trickster. InfluxDB Trickster 1.0 has support for InfluxDB. Specify 'influxdb' as the Origin Type when configuring Trickster. See the InfluxDB Support Document for more information. ClickHouse Trickster 1.0 has support for ClickHouse. Specify 'clickhouse' as the Origin Type when configuring Trickster. See the ClickHouse Support Document for more information. Circonus IRONdb Support has been included for the Circonus IRONdb time-series database. If Grafana is used for visualizations, the Circonus IRONdb data source plug-in for Grafana can be configured to use Trickster as its data source. All IRONdb data retrieval operations, including CAQL queries, are supported. When configuring an IRONdb origin, specify 'irondb' as the origin type in the Trickster configuration. The host value can be set directly to the address and port of an IRONdb node, but it is recommended to use the Circonus API proxy service. When using the proxy service, set the host value to the address and port of the proxy service, and set the api_path value to 'irondb' .","title":"Supported Origin Types"},{"location":"supported-origin-types/#supported-origin-types","text":"Trickster currently supports the following Origin Types:","title":"Supported Origin Types"},{"location":"supported-origin-types/#generic-http-reverse-proxy-cache","text":"Trickster operates as a fully-featured and highly-customizable reverse proxy cache, designed to accellerate and scale upstream endpoints like API services and other simple http services. Specify 'reverseproxycache' or just 'rpc' as the Origin Type when configuring Trickster.","title":" Generic HTTP Reverse Proxy Cache"},{"location":"supported-origin-types/#time-series-databases","text":"","title":"Time Series Databases"},{"location":"supported-origin-types/#prometheus","text":"Trickster fully supports the Prometheus HTTP API (v1) . Specify 'prometheus' as the Origin Type when configuring Trickster.","title":" Prometheus"},{"location":"supported-origin-types/#influxdb","text":"Trickster 1.0 has support for InfluxDB. Specify 'influxdb' as the Origin Type when configuring Trickster. See the InfluxDB Support Document for more information.","title":" InfluxDB"},{"location":"supported-origin-types/#clickhouse","text":"Trickster 1.0 has support for ClickHouse. Specify 'clickhouse' as the Origin Type when configuring Trickster. See the ClickHouse Support Document for more information.","title":" ClickHouse"},{"location":"supported-origin-types/#circonus-irondb","text":"Support has been included for the Circonus IRONdb time-series database. If Grafana is used for visualizations, the Circonus IRONdb data source plug-in for Grafana can be configured to use Trickster as its data source. All IRONdb data retrieval operations, including CAQL queries, are supported. When configuring an IRONdb origin, specify 'irondb' as the origin type in the Trickster configuration. The host value can be set directly to the address and port of an IRONdb node, but it is recommended to use the Circonus API proxy service. When using the proxy service, set the host value to the address and port of the proxy service, and set the api_path value to 'irondb' .","title":" Circonus IRONdb"},{"location":"tls/","text":"TLS Support Trickster supports TLS on both the frontend server and backend clients. Basics To enable the TLS server, you must specify the tls_listen_port , and optionally, the tls_listen_address in the [frontend] section of your config file. For example: [frontend] listen_port = 8480 tls_listen_port = 8483 Note, Trickster will only start listening on the TLS port if at least one origin has a valid certificate and key configured. Each origin section of a Trickster config file can be augmented with the optional tls section to modify TLS behavior for front-end and back-end requests. For example: [origins] [origins.example] # origin for example [origins.example.tls] # TLS settings for origin named example # front-end configs full_chain_cert_path = '/path/to/my/cert.pem' private_key_path = '/path/to/my/key.pem' # back-end configs insecure_skip_verify = true certificate_authority_paths = [ '/path/to/ca1.pem', '/path/to/ca2.pem' ] client_cert_path = '/path/to/client/cert.pem' client_key_path = '/path/to/client/key.pem' Front-End Each origin can handle encryption with exactly 1 certificate and key pair, as configured in the TLS section of the origin config (demonstrated above). If the path to any configured Certificate or Key file is unreachable or unparsable, Trickster will exit upon startup with an error providing reasonable context. You may use the same TLS certificate and key for multiple origins, depending upon how your Trickster configurations are laid out. Any certificates configured by Trickster must match the hostname header of the inbound http request (exactly, or by wildcard interpolation), or clients will likely reject the certificate for security issues. Back-End Each Trickster origin front-end configuration is paired with its own back-end http(s) client, which can be configured in the TLS section of the origin config, as demonstrated above. insecure_skip_verify will instruct the http client to ignore hostname verification issues with the upstream origin's certificate, and process the request anyway. This is analogous to -k | --insecure in curl. certificate_authority_paths will provide the http client with a list of certificate authorities (used in addition to any OS-provided root CA's) to use when determining the trust of an upstream origin's tls certificate. In all cases, the Root CA's installed to the operating system on which Trickster is running are used for trust by the client. To us Mutual Authentication with an upstream origin server, configure Trickster with Client Certificates using client_cert_path and client_key_path parameters, as shown above. You will likely need to also configure a custom CA in certificate_authority_paths to represent your certificate signer, unless it has been added to the underlying Operating System's CA list.","title":"TLS Support"},{"location":"tls/#tls-support","text":"Trickster supports TLS on both the frontend server and backend clients.","title":"TLS Support"},{"location":"tls/#basics","text":"To enable the TLS server, you must specify the tls_listen_port , and optionally, the tls_listen_address in the [frontend] section of your config file. For example: [frontend] listen_port = 8480 tls_listen_port = 8483 Note, Trickster will only start listening on the TLS port if at least one origin has a valid certificate and key configured. Each origin section of a Trickster config file can be augmented with the optional tls section to modify TLS behavior for front-end and back-end requests. For example: [origins] [origins.example] # origin for example [origins.example.tls] # TLS settings for origin named example # front-end configs full_chain_cert_path = '/path/to/my/cert.pem' private_key_path = '/path/to/my/key.pem' # back-end configs insecure_skip_verify = true certificate_authority_paths = [ '/path/to/ca1.pem', '/path/to/ca2.pem' ] client_cert_path = '/path/to/client/cert.pem' client_key_path = '/path/to/client/key.pem'","title":"Basics"},{"location":"tls/#front-end","text":"Each origin can handle encryption with exactly 1 certificate and key pair, as configured in the TLS section of the origin config (demonstrated above). If the path to any configured Certificate or Key file is unreachable or unparsable, Trickster will exit upon startup with an error providing reasonable context. You may use the same TLS certificate and key for multiple origins, depending upon how your Trickster configurations are laid out. Any certificates configured by Trickster must match the hostname header of the inbound http request (exactly, or by wildcard interpolation), or clients will likely reject the certificate for security issues.","title":"Front-End"},{"location":"tls/#back-end","text":"Each Trickster origin front-end configuration is paired with its own back-end http(s) client, which can be configured in the TLS section of the origin config, as demonstrated above. insecure_skip_verify will instruct the http client to ignore hostname verification issues with the upstream origin's certificate, and process the request anyway. This is analogous to -k | --insecure in curl. certificate_authority_paths will provide the http client with a list of certificate authorities (used in addition to any OS-provided root CA's) to use when determining the trust of an upstream origin's tls certificate. In all cases, the Root CA's installed to the operating system on which Trickster is running are used for trust by the client. To us Mutual Authentication with an upstream origin server, configure Trickster with Client Certificates using client_cert_path and client_key_path parameters, as shown above. You will likely need to also configure a custom CA in certificate_authority_paths to represent your certificate signer, unless it has been added to the underlying Operating System's CA list.","title":"Back-End"},{"location":"tracing/","text":"Distributed Tracing via OpenTelemetry Trickster instruments Distributed Tracing with OpenTelemetry , which is a currently emergent, comprehensive observability stack that is in Public Beta. We import the OpenTelemetry golang packages to instrument support for tracing. As OpenTelemetry evolves to support additional exporter formats, we will work to extend Trickster to support those as quickly as possible. We also make a best effort to update our otel package imports to the latest releases, whenever we publish a new Trickster release. You can check the go.mod file to see which release of opentelemetry-go we are is using. In this view, to see which version of otel a specific Trickster release imports, use the branch selector dropdown to switch to the tag corresponding to that version of Trickster. Supported Tracing Backends Jaeger Jaeger Agent Zipkin Console/Stdout (printed locally by the Trickster process) Configuration Trickster allows the operator to configure multiple tracing configurations, which can be associated into each Origin configuration by name. The example config has exhaustive examples of configuring Trickster for distributed tracing. Span List Trickster can insert several spans to the traces that it captures, depending upon the type and cacheability of the inbound client request, as described in the table below. Span Name Observes when Trickster is: request initially handling the client request by an Origin QueryCache querying the cache for an object WriteCache writing an object to the cache DeltaProxyCacheRequest handling a Time Series-based client request FastForward making a Fast Forward request for time series data ProxyRequest communicating with an Origin server to fulfill a client request PrepareFetchReader preparing a client response from a cached or Origin response CacheRevalidation revalidating a stale cache object against its Origin FetchObject retrieving a non-time-series object from an Origin Tags / Attributes Trickster supports adding custom tags to every span via the configuration. Depending upon your preferred tracing backend, these may be referred to as attributes. See the example config for examples of adding custom attributes. Trickster also supports omitting any tags that Trickster inserts by default. The list of default tags are below. For example on the \"request\" span, an http.url tag is attached with the current full URL. In deployments where that tag may introduce too much cardinality in your backend trace storage system, you may wish to omit that tag and rely on the more concise path tag. Each tracer config can be provided a string list of tags to omit from traces. Attributes added to top level (request) span http.url - the full HTTP request URL origin.name origin.type cache.name cache.type router.path - request path trimmed to the route match path for the request (e.g., /api/v1/query ), good for aggregating when there are large variations in the full URL path Attributes added to QueryCache span cache.status - the lookup status of cache query. See the cache status reference for a description of the attribute values. Attributes added to the FetchRevalidation span isRange - is true if the client request includes an HTTP Range header Attributes added to the FetchObject span isPCF - is true if the origin is configured for Progressive Collapsed Forwarding","title":"Distributed Tracing via OpenTelemetry"},{"location":"tracing/#distributed-tracing-via-opentelemetry","text":"Trickster instruments Distributed Tracing with OpenTelemetry , which is a currently emergent, comprehensive observability stack that is in Public Beta. We import the OpenTelemetry golang packages to instrument support for tracing. As OpenTelemetry evolves to support additional exporter formats, we will work to extend Trickster to support those as quickly as possible. We also make a best effort to update our otel package imports to the latest releases, whenever we publish a new Trickster release. You can check the go.mod file to see which release of opentelemetry-go we are is using. In this view, to see which version of otel a specific Trickster release imports, use the branch selector dropdown to switch to the tag corresponding to that version of Trickster.","title":"Distributed Tracing via OpenTelemetry"},{"location":"tracing/#supported-tracing-backends","text":"Jaeger Jaeger Agent Zipkin Console/Stdout (printed locally by the Trickster process)","title":"Supported Tracing Backends"},{"location":"tracing/#configuration","text":"Trickster allows the operator to configure multiple tracing configurations, which can be associated into each Origin configuration by name. The example config has exhaustive examples of configuring Trickster for distributed tracing.","title":"Configuration"},{"location":"tracing/#span-list","text":"Trickster can insert several spans to the traces that it captures, depending upon the type and cacheability of the inbound client request, as described in the table below. Span Name Observes when Trickster is: request initially handling the client request by an Origin QueryCache querying the cache for an object WriteCache writing an object to the cache DeltaProxyCacheRequest handling a Time Series-based client request FastForward making a Fast Forward request for time series data ProxyRequest communicating with an Origin server to fulfill a client request PrepareFetchReader preparing a client response from a cached or Origin response CacheRevalidation revalidating a stale cache object against its Origin FetchObject retrieving a non-time-series object from an Origin","title":"Span List"},{"location":"tracing/#tags-attributes","text":"Trickster supports adding custom tags to every span via the configuration. Depending upon your preferred tracing backend, these may be referred to as attributes. See the example config for examples of adding custom attributes. Trickster also supports omitting any tags that Trickster inserts by default. The list of default tags are below. For example on the \"request\" span, an http.url tag is attached with the current full URL. In deployments where that tag may introduce too much cardinality in your backend trace storage system, you may wish to omit that tag and rely on the more concise path tag. Each tracer config can be provided a string list of tags to omit from traces.","title":"Tags / Attributes"},{"location":"tracing/#attributes-added-to-top-level-request-span","text":"http.url - the full HTTP request URL origin.name origin.type cache.name cache.type router.path - request path trimmed to the route match path for the request (e.g., /api/v1/query ), good for aggregating when there are large variations in the full URL path","title":"Attributes added to top level (request) span"},{"location":"tracing/#attributes-added-to-querycache-span","text":"cache.status - the lookup status of cache query. See the cache status reference for a description of the attribute values.","title":"Attributes added to QueryCache span"},{"location":"tracing/#attributes-added-to-the-fetchrevalidation-span","text":"isRange - is true if the client request includes an HTTP Range header","title":"Attributes added to the FetchRevalidation span"},{"location":"tracing/#attributes-added-to-the-fetchobject-span","text":"isPCF - is true if the origin is configured for Progressive Collapsed Forwarding","title":"Attributes added to the FetchObject span"},{"location":"developer/adding-new-config/","text":"Adding a New Configuration Value Trickster configurations are defined in ./internal/config/ and are mapped to toml annotations. When adding a configuration value, there are several places to add references, which are described below. Configuration Code Each new configuration value must be defined in the config package under an existing Configuration collection (Origins, Caches, Paths, etc.). Make sure the TOML annotation uses a lowercase_no_spaces naming convention, while the configuration member name itself should be CamelCase . Follow the existing configs for guidance. Once you have defined the configuration member, if it is part of a CacheConfig , OriginConfig or PathConfig , it must also be added to the configuration parser for the specific type of configuration. These methods iterate through known TOML annoations to survey which configs have been set. This allows Trickster to know if a value is set because it is the initialized default value or because the operator has explicitly set it. Feature Code Once you have defined your configuration value(s), you must put them to work by referencing them elsewhere in the Trickster code, and used to determine or customize the application functionality. Exactly where this happens in the code depends upon the context and reach or your new configuration, and what features its state affects. Consult with a project maintainer if you have any questions. Tests All new values that you add should have accompanying unit tests to ensure the modifications the value makes to the application in the feature code work as designed. Unit Tests should include verification of: proper parsing of configuration value from test config files (in ./testdata), correct feature functionality enable/disable based on the configuration value, correct feature implementation, coverage of all executable lines of code. Unit Test will span the config package, and any package(s) wherein the configuration value is used by the applciation. Documentation The feature should be documented under ./docs directory, in a suitable existing or new markdown file based on the nature of the feature. The documentation should show the key example configuration options and describe their expected results, and point to the example config file for more information. The example config file (./cmd/trickster/conf/example.conf) should be updated to include the exhaustive description and options for the configuration value(s). Deployment The ./deply/kube/configmap.yaml must be updated to include the new configuration option(s). Generally this file contains a copy/paste of ./cmd/trickster/conf/example.conf . The ./deploy/helm/trickster/values.yaml file must be updated to mirror the configuration option(s) in the example.conf, and ./deploy/helm/trickster/templates/configmap.yaml must be updated to map any new yamlCaseValues to their respective toml_style_values for config file generation via the template.","title":"Adding a New Configuration Value"},{"location":"developer/adding-new-config/#adding-a-new-configuration-value","text":"Trickster configurations are defined in ./internal/config/ and are mapped to toml annotations. When adding a configuration value, there are several places to add references, which are described below.","title":"Adding a New Configuration Value"},{"location":"developer/adding-new-config/#configuration-code","text":"Each new configuration value must be defined in the config package under an existing Configuration collection (Origins, Caches, Paths, etc.). Make sure the TOML annotation uses a lowercase_no_spaces naming convention, while the configuration member name itself should be CamelCase . Follow the existing configs for guidance. Once you have defined the configuration member, if it is part of a CacheConfig , OriginConfig or PathConfig , it must also be added to the configuration parser for the specific type of configuration. These methods iterate through known TOML annoations to survey which configs have been set. This allows Trickster to know if a value is set because it is the initialized default value or because the operator has explicitly set it.","title":"Configuration Code"},{"location":"developer/adding-new-config/#feature-code","text":"Once you have defined your configuration value(s), you must put them to work by referencing them elsewhere in the Trickster code, and used to determine or customize the application functionality. Exactly where this happens in the code depends upon the context and reach or your new configuration, and what features its state affects. Consult with a project maintainer if you have any questions.","title":"Feature Code"},{"location":"developer/adding-new-config/#tests","text":"All new values that you add should have accompanying unit tests to ensure the modifications the value makes to the application in the feature code work as designed. Unit Tests should include verification of: proper parsing of configuration value from test config files (in ./testdata), correct feature functionality enable/disable based on the configuration value, correct feature implementation, coverage of all executable lines of code. Unit Test will span the config package, and any package(s) wherein the configuration value is used by the applciation.","title":"Tests"},{"location":"developer/adding-new-config/#documentation","text":"The feature should be documented under ./docs directory, in a suitable existing or new markdown file based on the nature of the feature. The documentation should show the key example configuration options and describe their expected results, and point to the example config file for more information. The example config file (./cmd/trickster/conf/example.conf) should be updated to include the exhaustive description and options for the configuration value(s).","title":"Documentation"},{"location":"developer/adding-new-config/#deployment","text":"The ./deply/kube/configmap.yaml must be updated to include the new configuration option(s). Generally this file contains a copy/paste of ./cmd/trickster/conf/example.conf . The ./deploy/helm/trickster/values.yaml file must be updated to mirror the configuration option(s) in the example.conf, and ./deploy/helm/trickster/templates/configmap.yaml must be updated to map any new yamlCaseValues to their respective toml_style_values for config file generation via the template.","title":"Deployment"},{"location":"developer/origin-extensibility/","text":"Extending Trickster to Support a New Origin Type Trickster 1.0 was written with extensibility in mind, and should be able to work with any time series database that has an HTTP-based API. In Trickster, we generically refer to our supported TSDB's as Origin Types. Some Origin Types are easier to implement and maintain than others, depending upon a host of factors that are covered later in this document. This document is meant to help anyone wishing to extend Trickster to support a new Origin Type, particularly in gauging the level of effort, understanding what is involved, and implementing the required interfaces and rules. Qualifications Not every database server out there is a candidate for being fronted by Trickster. Trickster serves the specific purpose of accelerating the delivery of time series data sets, and will not benefit traditional relational databases, NoSQL, etc. As mentioned, the database must be able to be queried for and return time series data via HTTP. Some databases that are not specifically TSDB's actually do support querying for and returning data in a time series format, and Trickster will support those cases as detailed below, so long as they have an HTTP API. Skills Needed In addition to these requirements in the technology, there are also skills qualifications to consider. Whether or not you've contributed to Open Source Software before, take a look at our Contributing guidelines so you know how the process works for the Trickster project. If you are unfamiliar with the Forking Workflow, read up on it so that you are able to contribute to the project through Pull Requests. Trickster is a 100% Go project, so you will need to have experience writing in Go, and in particular, data marshaling/unmarshaling and data set manipulation (sorting, merging, cropping, de-duplicating, etc.). You will need to have a good understanding of the prospective Origin Type's query language and response payload structure, so you can write the necessary parsing and modeling methods that allow Trickster to manipulate upstream HTTP requests and merge newly fetched data sets into the cache. While this might sound daunting, it is actually much easier than it appears on the surface. Since Trickster's DeltaProxyCache engine does a lot of the heavy lifting, you only have to write a series of interface functions before finding yourself near the finish line. And since a few Origin Types are already implemented, you can use their implementations for references, since the logic for your prospective Origin Type should be similar. Interfaces Trickster provides 2 required interfaces for enabling a new Origin Type: The Proxy Client and the Time Series Proxy Client Interface The Proxy Client Interface ( code ) is used by Trickster to manipulate HTTP requests and responses in order to accelerate the requests. For your Proxy Client Implementation, you will need to know these things about the Origin: What URL paths and methods must be supported, and which engine through which to route each path (Basic HTTP Proxy, Object Proxy Cache, or Time Series Delta Proxy Cache). The proxy engines will call your client implementation's interface exports in order to service user requests. What data inputs the origin expects (Path, URL parameters, POST Data, HTTP Headers, cookies, etc.), and how to manipulate the query's time range when constructing those inputs to achieve a desired result. The Proxy Client Interface Methods you will need to implement are broken into several groups of functionality, as follows. Basic Getters Configuration returns the *config.OriginConfig object for the origin. Name returns the configured name of the Origin Type instance. HTTPClient returns the reusable *http.Client object that communicates with the Origin. HTTP Request Routing and Handling RegisterRoutes registers all of the HTTP Paths that will be used by the Origin Type and map them to handlers written to service the various paths. HealthHandler this method is a standard HTTP Handler that can verify and report back the health of the upstream origin and the proxy's connection to it. You will certainly create at least one other handler in your Origin Type package, but this is the only one required for conformance to the Proxy Client interface. Caching DeriveCacheKey inspects the client request and returns the corresponding cache key Time Series Handling UnmarshalTimeseries deserializes an HTTP Response time series payload into a Go struct MarshalTimeseries seralizes a time-series struct into a serialized byte slice. UnmarshalInstantaneous deserializes an HTTP Response instantaneous payload into a Go struct. This may not be applicable to every potential Origin Type. ParseTimeRangeQuery inspects the client request and returns a corresponding timeseries.TimeRangeQuery SetExtent updates an upstream request's time range parameters as needed based on the delta gap analysis FastForwardURL returns the URL to the origin to collect Fast Forward data points based on the provided HTTP Request Time Series Interface The Time Series Interface ( code ) is used by Trickster to manipulate Time Series documents in order to maintain the cache and construct downstream client request bodies. For your Time Series Implementation, you will need to know these things about the Origin: The structure of the response payload and how that translates into Go structs. More often than not, a prospective Origin Type offers an importable model to assist with this. The Time Series Interface Methods you will need to implement are broken into several groups of functionality, as follows. Getters Extents returns a list of the time ranges present in the cache Step returns the Step (the duration between each timestamp in the series) SeriesCount returns the number of series (e.g., graph lines) in the data set ValueCount returns the total number of values across all series in the data set Setters SetExtents sets the list of the time ranges present in the cache SetStep sets the Step Data Set Manipulation Merge merges a variadic list of time series into the base time series Sort chronologically sorts the values in each series in the time series Copy makes an new exact copy of the time series Crop removes any values from the time series that are outside of the provided time range Special Considerations Query Language Complexity One of the main areas of consideration is the complexity of parsing and manipulating an inbound query. You will need to (1) determine if it is indeed a request for a timeseries; and if so (2) extract the requested time range and step duration for the query; and in the event of a partial cache hit, (3) adjust the time range for the query to a provided range - all of which allows the DeltaProxyCache to fetch just the needed sections of data from the upstream origin. Requirements 1 and 2 are functionality in ParseTimeRangeQuery while requirement 3 is the functionality of SetExtent . The overall complexity of this process can significantly affect the level of effort required to implement a new Origin Type. In the example of Prometheus, the process was extremely simple: since, in the Prometheus HTTP API, time range queries have a separate http endpoint path from instantaneous queries, and because the time range is provided as separate query parameters from the query itself, the range is easily modified without Trickster having any knowledge of the underlying query or having to even parse it at all. In the example of ClickHouse, the process is much harder: since the query language is a variant of SQL standard, the requested time ranges are embedded into the query itself behind the WHERE clause. In cases such as this, Trickster must have some way, either through (1) importing a database package that can deserialize the query, allow manipulation, and serialize the modified query for you; or (2) new parsing and search/replacement logic introduced in your own package - which allows the Client to interpret the time range and modify it with time ranges provided by the DeltaProxyCache. With ClickHouse, since it is a C++ project and Trickster is Golang, we could not import any package to handle this work, so we crafted a regular expression to match against inbound queries. This regex extracts the timerange (and any ClickHouse time modifiers like startOfMinute ) and step value as well as any other areas that include the timerange, and then use simple builtin string functions to inject tokens in place of specific ranges in the provided query. Then, when SetExtent is called, those tokens are search/replaced with the provided time values. Data Model Considerations Once you have the Client Interface implementation down and can interact with the upstream HTTP API, you will turn your attention to managing the response payload data and what to do with it, and that happens in your Timeseries Interface implementation. And like the Client interface, it will come with its own unique challenges. The main consideration here is the format of the output and what challenges are presented by it. For example, does the payload include any required metadata (e.g., a count of total rows returned) that you will need to synthesize within your Timeseries after a Merge , etc. Going back to the ClickHouse example, since it is a columnar database that happens to have time aggregation functions, there are a million ways to formulate a query that yields time series results. That can have implications on the resulting dataset: which fields are the time and value fields, and what are the rest? Are all datapoints for all the series in a single large slice or have they been segregated into their own slices? Is the Timestamp in Epoch format, and if so, does it represent seconds or milliseconds? In order to support an upstream database, you may need to establish or adopt guidelines around these and other questions to ensure full compatibility. The ClickHouse plugin for Grafana requires that for each datapoint of the response, the first field is the timestamp and the second field is the numeric value - so we adopt and document the same guideline to conform to existing norms. Getting More Help On the Gophers Slack instance, you can find us on the #trickster channel for any help you may need.","title":"Extending Trickster to Support a New Origin Type"},{"location":"developer/origin-extensibility/#extending-trickster-to-support-a-new-origin-type","text":"Trickster 1.0 was written with extensibility in mind, and should be able to work with any time series database that has an HTTP-based API. In Trickster, we generically refer to our supported TSDB's as Origin Types. Some Origin Types are easier to implement and maintain than others, depending upon a host of factors that are covered later in this document. This document is meant to help anyone wishing to extend Trickster to support a new Origin Type, particularly in gauging the level of effort, understanding what is involved, and implementing the required interfaces and rules.","title":"Extending Trickster to Support a New Origin Type"},{"location":"developer/origin-extensibility/#qualifications","text":"Not every database server out there is a candidate for being fronted by Trickster. Trickster serves the specific purpose of accelerating the delivery of time series data sets, and will not benefit traditional relational databases, NoSQL, etc. As mentioned, the database must be able to be queried for and return time series data via HTTP. Some databases that are not specifically TSDB's actually do support querying for and returning data in a time series format, and Trickster will support those cases as detailed below, so long as they have an HTTP API.","title":"Qualifications"},{"location":"developer/origin-extensibility/#skills-needed","text":"In addition to these requirements in the technology, there are also skills qualifications to consider. Whether or not you've contributed to Open Source Software before, take a look at our Contributing guidelines so you know how the process works for the Trickster project. If you are unfamiliar with the Forking Workflow, read up on it so that you are able to contribute to the project through Pull Requests. Trickster is a 100% Go project, so you will need to have experience writing in Go, and in particular, data marshaling/unmarshaling and data set manipulation (sorting, merging, cropping, de-duplicating, etc.). You will need to have a good understanding of the prospective Origin Type's query language and response payload structure, so you can write the necessary parsing and modeling methods that allow Trickster to manipulate upstream HTTP requests and merge newly fetched data sets into the cache. While this might sound daunting, it is actually much easier than it appears on the surface. Since Trickster's DeltaProxyCache engine does a lot of the heavy lifting, you only have to write a series of interface functions before finding yourself near the finish line. And since a few Origin Types are already implemented, you can use their implementations for references, since the logic for your prospective Origin Type should be similar.","title":"Skills Needed"},{"location":"developer/origin-extensibility/#interfaces","text":"Trickster provides 2 required interfaces for enabling a new Origin Type: The Proxy Client and the Time Series","title":"Interfaces"},{"location":"developer/origin-extensibility/#proxy-client-interface","text":"The Proxy Client Interface ( code ) is used by Trickster to manipulate HTTP requests and responses in order to accelerate the requests. For your Proxy Client Implementation, you will need to know these things about the Origin: What URL paths and methods must be supported, and which engine through which to route each path (Basic HTTP Proxy, Object Proxy Cache, or Time Series Delta Proxy Cache). The proxy engines will call your client implementation's interface exports in order to service user requests. What data inputs the origin expects (Path, URL parameters, POST Data, HTTP Headers, cookies, etc.), and how to manipulate the query's time range when constructing those inputs to achieve a desired result. The Proxy Client Interface Methods you will need to implement are broken into several groups of functionality, as follows.","title":"Proxy Client Interface"},{"location":"developer/origin-extensibility/#basic-getters","text":"Configuration returns the *config.OriginConfig object for the origin. Name returns the configured name of the Origin Type instance. HTTPClient returns the reusable *http.Client object that communicates with the Origin.","title":"Basic Getters"},{"location":"developer/origin-extensibility/#http-request-routing-and-handling","text":"RegisterRoutes registers all of the HTTP Paths that will be used by the Origin Type and map them to handlers written to service the various paths. HealthHandler this method is a standard HTTP Handler that can verify and report back the health of the upstream origin and the proxy's connection to it. You will certainly create at least one other handler in your Origin Type package, but this is the only one required for conformance to the Proxy Client interface.","title":"HTTP Request Routing and Handling"},{"location":"developer/origin-extensibility/#caching","text":"DeriveCacheKey inspects the client request and returns the corresponding cache key","title":"Caching"},{"location":"developer/origin-extensibility/#time-series-handling","text":"UnmarshalTimeseries deserializes an HTTP Response time series payload into a Go struct MarshalTimeseries seralizes a time-series struct into a serialized byte slice. UnmarshalInstantaneous deserializes an HTTP Response instantaneous payload into a Go struct. This may not be applicable to every potential Origin Type. ParseTimeRangeQuery inspects the client request and returns a corresponding timeseries.TimeRangeQuery SetExtent updates an upstream request's time range parameters as needed based on the delta gap analysis FastForwardURL returns the URL to the origin to collect Fast Forward data points based on the provided HTTP Request","title":"Time Series Handling"},{"location":"developer/origin-extensibility/#time-series-interface","text":"The Time Series Interface ( code ) is used by Trickster to manipulate Time Series documents in order to maintain the cache and construct downstream client request bodies. For your Time Series Implementation, you will need to know these things about the Origin: The structure of the response payload and how that translates into Go structs. More often than not, a prospective Origin Type offers an importable model to assist with this. The Time Series Interface Methods you will need to implement are broken into several groups of functionality, as follows.","title":"Time Series Interface"},{"location":"developer/origin-extensibility/#getters","text":"Extents returns a list of the time ranges present in the cache Step returns the Step (the duration between each timestamp in the series) SeriesCount returns the number of series (e.g., graph lines) in the data set ValueCount returns the total number of values across all series in the data set","title":"Getters"},{"location":"developer/origin-extensibility/#setters","text":"SetExtents sets the list of the time ranges present in the cache SetStep sets the Step","title":"Setters"},{"location":"developer/origin-extensibility/#data-set-manipulation","text":"Merge merges a variadic list of time series into the base time series Sort chronologically sorts the values in each series in the time series Copy makes an new exact copy of the time series Crop removes any values from the time series that are outside of the provided time range","title":"Data Set Manipulation"},{"location":"developer/origin-extensibility/#special-considerations","text":"","title":"Special Considerations"},{"location":"developer/origin-extensibility/#query-language-complexity","text":"One of the main areas of consideration is the complexity of parsing and manipulating an inbound query. You will need to (1) determine if it is indeed a request for a timeseries; and if so (2) extract the requested time range and step duration for the query; and in the event of a partial cache hit, (3) adjust the time range for the query to a provided range - all of which allows the DeltaProxyCache to fetch just the needed sections of data from the upstream origin. Requirements 1 and 2 are functionality in ParseTimeRangeQuery while requirement 3 is the functionality of SetExtent . The overall complexity of this process can significantly affect the level of effort required to implement a new Origin Type. In the example of Prometheus, the process was extremely simple: since, in the Prometheus HTTP API, time range queries have a separate http endpoint path from instantaneous queries, and because the time range is provided as separate query parameters from the query itself, the range is easily modified without Trickster having any knowledge of the underlying query or having to even parse it at all. In the example of ClickHouse, the process is much harder: since the query language is a variant of SQL standard, the requested time ranges are embedded into the query itself behind the WHERE clause. In cases such as this, Trickster must have some way, either through (1) importing a database package that can deserialize the query, allow manipulation, and serialize the modified query for you; or (2) new parsing and search/replacement logic introduced in your own package - which allows the Client to interpret the time range and modify it with time ranges provided by the DeltaProxyCache. With ClickHouse, since it is a C++ project and Trickster is Golang, we could not import any package to handle this work, so we crafted a regular expression to match against inbound queries. This regex extracts the timerange (and any ClickHouse time modifiers like startOfMinute ) and step value as well as any other areas that include the timerange, and then use simple builtin string functions to inject tokens in place of specific ranges in the provided query. Then, when SetExtent is called, those tokens are search/replaced with the provided time values.","title":"Query Language Complexity"},{"location":"developer/origin-extensibility/#data-model-considerations","text":"Once you have the Client Interface implementation down and can interact with the upstream HTTP API, you will turn your attention to managing the response payload data and what to do with it, and that happens in your Timeseries Interface implementation. And like the Client interface, it will come with its own unique challenges. The main consideration here is the format of the output and what challenges are presented by it. For example, does the payload include any required metadata (e.g., a count of total rows returned) that you will need to synthesize within your Timeseries after a Merge , etc. Going back to the ClickHouse example, since it is a columnar database that happens to have time aggregation functions, there are a million ways to formulate a query that yields time series results. That can have implications on the resulting dataset: which fields are the time and value fields, and what are the rest? Are all datapoints for all the series in a single large slice or have they been segregated into their own slices? Is the Timestamp in Epoch format, and if so, does it represent seconds or milliseconds? In order to support an upstream database, you may need to establish or adopt guidelines around these and other questions to ensure full compatibility. The ClickHouse plugin for Grafana requires that for each datapoint of the response, the first field is the timestamp and the second field is the numeric value - so we adopt and document the same guideline to conform to existing norms.","title":"Data Model Considerations"},{"location":"developer/origin-extensibility/#getting-more-help","text":"On the Gophers Slack instance, you can find us on the #trickster channel for any help you may need.","title":"Getting More Help"},{"location":"developer/spinning-new-release/","text":"Spinning New Trickster Release Users with push access to tricksterproxy/trickster (maintainers and owners) can spin releases. To spin a new Trickster release, clone the repo, checkout the commit ID for the release, tag it with a release in semantic version format ( vX.Y.Z ), and push the tag back to the GitHub repository. GitHub actions will detect the publishing of the new tag (so long as it's in the proper format) and cut a full release for the tag automatically.","title":"Spinning New Trickster Release"},{"location":"developer/spinning-new-release/#spinning-new-trickster-release","text":"Users with push access to tricksterproxy/trickster (maintainers and owners) can spin releases. To spin a new Trickster release, clone the repo, checkout the commit ID for the release, tag it with a release in semantic version format ( vX.Y.Z ), and push the tag back to the GitHub repository. GitHub actions will detect the publishing of the new tag (so long as it's in the proper format) and cut a full release for the tag automatically.","title":"Spinning New Trickster Release"},{"location":"developer/tracing/","text":"Tracing support Trickster has minimal support for OpenTelemetry. See https://github.com/tricksterproxy/trickster/issues/36 Config TODO Developer Testing Manual with Jaeger Start jaeger docker run -d --name jaeger \\ () -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \\ -p 5775:5775/udp \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 14268:14268 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1. Star Promsim From the Trickster root run go run cmd/promsim/main.go Start Trickster with tracing test config From the Trickster root run make build -o trickster && ./OPATH/trickster -config testdata/test.tracing.conf --log-level debug Query curl -i 'localhost:8080/test/api/v1/query_range?query=my_test_query{random_label=\"57\",series_count=\"1\"}&start=2&end=4&step=1' Visit Jaeger UI at http://localhost:16686/search Testing Utilities tracing.Recorder is a trace exporter for capturing exported trace spans for inspection later. tracing.TestHTTPClient is an http client with a mock http.RoundTripper that calls a test handler for faking http calls. SetupTestingTracer uses the above type to setup a mock tracer whose spans can be validated. Usage together (from recorder_test.go : flush, ctx, recorder, tr := SetupTestingTracer(t, RecorderTracer, 1.0, TestContextValues) err := tr.WithSpan(ctx, \"Testing trace with span\", func(ctx context.Context) error { var ( err error ) req, _ := http.NewRequest(\"GET\", \"https://example.com/test\", nil) ctx, req = httptrace.W3C(ctx, req) httptrace.Inject(ctx, req) _, err = TestHTTPClient().Do(req) if err != nil { return err } SpanFromContext(ctx).SetStatus(codes.OK) return nil }) assert.NoError(t, err, \"failed to inject span\") flush() m := make(map[string]string) for _, kv := range TestEvents { m[string(kv.Key)] = kv.Value.Emit() } for _, span := range recorder.spans { for _, msg := range span.MessageEvents { for _, attr := range msg.Attributes { key := string(attr.Key) wantV, ok := m[key] assert.True(t, ok, \"kv not in known good map\") v := attr.Value.Emit() assert.Equal(t, wantV, v, \"Span Message attribute value incorrect\") } } }","title":"Tracing support"},{"location":"developer/tracing/#tracing-support","text":"Trickster has minimal support for OpenTelemetry. See https://github.com/tricksterproxy/trickster/issues/36","title":"Tracing support"},{"location":"developer/tracing/#config","text":"TODO","title":"Config"},{"location":"developer/tracing/#developer-testing","text":"","title":"Developer Testing"},{"location":"developer/tracing/#manual-with-jaeger","text":"Start jaeger docker run -d --name jaeger \\ () -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \\ -p 5775:5775/udp \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 14268:14268 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1. Star Promsim From the Trickster root run go run cmd/promsim/main.go Start Trickster with tracing test config From the Trickster root run make build -o trickster && ./OPATH/trickster -config testdata/test.tracing.conf --log-level debug Query curl -i 'localhost:8080/test/api/v1/query_range?query=my_test_query{random_label=\"57\",series_count=\"1\"}&start=2&end=4&step=1' Visit Jaeger UI at http://localhost:16686/search","title":"Manual with Jaeger"},{"location":"developer/tracing/#testing-utilities","text":"tracing.Recorder is a trace exporter for capturing exported trace spans for inspection later. tracing.TestHTTPClient is an http client with a mock http.RoundTripper that calls a test handler for faking http calls. SetupTestingTracer uses the above type to setup a mock tracer whose spans can be validated. Usage together (from recorder_test.go : flush, ctx, recorder, tr := SetupTestingTracer(t, RecorderTracer, 1.0, TestContextValues) err := tr.WithSpan(ctx, \"Testing trace with span\", func(ctx context.Context) error { var ( err error ) req, _ := http.NewRequest(\"GET\", \"https://example.com/test\", nil) ctx, req = httptrace.W3C(ctx, req) httptrace.Inject(ctx, req) _, err = TestHTTPClient().Do(req) if err != nil { return err } SpanFromContext(ctx).SetStatus(codes.OK) return nil }) assert.NoError(t, err, \"failed to inject span\") flush() m := make(map[string]string) for _, kv := range TestEvents { m[string(kv.Key)] = kv.Value.Emit() } for _, span := range recorder.spans { for _, msg := range span.MessageEvents { for _, attr := range msg.Attributes { key := string(attr.Key) wantV, ok := m[key] assert.True(t, ok, \"kv not in known good map\") v := attr.Value.Emit() assert.Equal(t, wantV, v, \"Span Message attribute value incorrect\") } } }","title":"Testing Utilities"}]}